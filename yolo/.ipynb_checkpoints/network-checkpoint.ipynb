{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 26+10+4   #Grossbuchstaben, Zahlen, {.:/-}\n",
    "anchors = [10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326]\n",
    "leaky_relu_value = 0.1\n",
    "anchor_number = np.size(anchors)/6\n",
    "features = int(anchor_number*(4+1+classes))\n",
    "dimension = 3\n",
    "\n",
    "\n",
    "class Yolo_v3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Yolo_v3, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(dimension,32,3,stride=1,padding=1)\n",
    "        self.batch_1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(32,64,3,stride=2,padding=1)\n",
    "        self.batch_2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(64,32,1,stride=1,padding=0)\n",
    "        self.batch_3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv_4 = nn.Conv2d(32,64,3,stride=1,padding=1)\n",
    "        self.batch_4 = nn.BatchNorm2d(64)\n",
    "\n",
    "\n",
    "        \n",
    "        self.conv_6 = nn.Conv2d(64,128,3,stride=2,padding=1)\n",
    "        self.batch_6 = nn.BatchNorm2d(128)\n",
    "            \n",
    "        self.conv_7 = nn.Conv2d(128,64,1,stride=1,padding=0)\n",
    "        self.batch_7 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_8 = nn.Conv2d(64,128,3,stride=1,padding=1)\n",
    "        self.batch_8 = nn.BatchNorm2d(128)\n",
    " \n",
    "\n",
    "          \n",
    "        self.conv_10 = nn.Conv2d(128,64,1,stride=1,padding=0)\n",
    "        self.batch_10 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_11 = nn.Conv2d(64,128,3,stride=1,padding=1)\n",
    "        self.batch_11 = nn.BatchNorm2d(128)\n",
    "          \n",
    "\n",
    "             \n",
    "        self.conv_13 = nn.Conv2d(128,256,3,stride=2,padding=1)\n",
    "        self.batch_13 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_14 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_14 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_15 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_15 = nn.BatchNorm2d(256)        \n",
    "        \n",
    "\n",
    "\n",
    "        self.conv_17 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_17 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_18 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_18 = nn.BatchNorm2d(256)\n",
    "        \n",
    "       \n",
    "    \n",
    "        \n",
    "        self.conv_38 = nn.Conv2d(256,512,3,stride=2,padding=1)\n",
    "        self.batch_38 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_39 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_39 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_40 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_40 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_42 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_42 = nn.BatchNorm2d(256)        \n",
    "        \n",
    "        self.conv_43 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_43 = nn.BatchNorm2d(512)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.conv_63 = nn.Conv2d(512,1024,3,stride=2,padding=1)\n",
    "        self.batch_63 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv_64 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_64 = nn.BatchNorm2d(512)        \n",
    "        \n",
    "        self.conv_65 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_65 = nn.BatchNorm2d(1024)  \n",
    "        \n",
    "\n",
    "        \n",
    "        self.conv_67 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_67 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_68 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_68 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_76 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_76 = nn.BatchNorm2d(512)        \n",
    "        \n",
    "        self.conv_77 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_77 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv_82 = nn.Conv2d(1024,features,1,stride=1,padding=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_85 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_85 = nn.BatchNorm2d(256)       \n",
    "\n",
    "        self.convT_86 = nn.ConvTranspose2d(256,256,3,stride=2,padding=1,output_padding=1)\n",
    "        self.batch_86 = nn.BatchNorm2d(256) \n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv_88 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_88 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_89 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_89 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_94 = nn.Conv2d(512,features,1,stride=1,padding=0)\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        self.conv_97 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_97 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.convT_98 = nn.ConvTranspose2d(128,128,3,stride=2,padding=1,output_padding=1)\n",
    "        self.batch_98 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_100 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_100 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_101 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_101 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_106 = nn.Conv2d(256,features,1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        layer_1 = F.leaky_relu(self.batch_1(self.conv_1(inputs)),leaky_relu_value,True)\n",
    "        layer_2 = F.leaky_relu(self.batch_2(self.conv_2(layer_1)),leaky_relu_value,True)\n",
    "        layer_3 = F.leaky_relu(self.batch_3(self.conv_3(layer_2)),leaky_relu_value,True)\n",
    "        layer_4 = F.leaky_relu(self.batch_4(self.conv_4(layer_3)),leaky_relu_value,True)\n",
    "        layer_5 = layer_2 + layer_4\n",
    "        layer_6 = F.leaky_relu(self.batch_6(self.conv_6(layer_5)),leaky_relu_value,True)\n",
    "        layer_7 = F.leaky_relu(self.batch_7(self.conv_7(layer_6)),leaky_relu_value,True)\n",
    "        layer_8 = F.leaky_relu(self.batch_8(self.conv_8(layer_7)),leaky_relu_value,True)\n",
    "        layer_9 = layer_6 + layer_8\n",
    "        layer_10 = F.leaky_relu(self.batch_10(self.conv_10(layer_9)),leaky_relu_value,True)\n",
    "        layer_11 = F.leaky_relu(self.batch_11(self.conv_11(layer_10)),leaky_relu_value,True)\n",
    "        layer_12 = layer_9 + layer_11\n",
    "        layer_13 = F.leaky_relu(self.batch_13(self.conv_13(layer_12)),leaky_relu_value,True)\n",
    "        layer_14 = F.leaky_relu(self.batch_14(self.conv_14(layer_13)),leaky_relu_value,True)\n",
    "        layer_15 = F.leaky_relu(self.batch_15(self.conv_15(layer_14)),leaky_relu_value,True)\n",
    "        layer_16 = layer_13 + layer_15\n",
    "        layer_17 = F.leaky_relu(self.batch_17(self.conv_17(layer_16)),leaky_relu_value,True)\n",
    "        layer_18 = F.leaky_relu(self.batch_18(self.conv_18(layer_17)),leaky_relu_value,True)\n",
    "        layer_19 = layer_16 + layer_18      \n",
    "        layer_20 = F.leaky_relu(self.batch_17(self.conv_17(layer_19)),leaky_relu_value,True)\n",
    "        layer_21 = F.leaky_relu(self.batch_18(self.conv_18(layer_20)),leaky_relu_value,True)\n",
    "        layer_22 = layer_19 + layer_21\n",
    "        layer_23 = F.leaky_relu(self.batch_17(self.conv_17(layer_22)),leaky_relu_value,True)\n",
    "        layer_24 = F.leaky_relu(self.batch_18(self.conv_18(layer_23)),leaky_relu_value,True)\n",
    "        layer_25 = layer_22 + layer_24\n",
    "        layer_26 = F.leaky_relu(self.batch_17(self.conv_17(layer_25)),leaky_relu_value,True)\n",
    "        layer_27 = F.leaky_relu(self.batch_18(self.conv_18(layer_26)),leaky_relu_value,True)\n",
    "        layer_28 = layer_25 + layer_27\n",
    "        layer_29 = F.leaky_relu(self.batch_17(self.conv_17(layer_28)),leaky_relu_value,True)\n",
    "        layer_30 = F.leaky_relu(self.batch_18(self.conv_18(layer_29)),leaky_relu_value,True)\n",
    "        layer_31 = layer_28 + layer_30\n",
    "        layer_32 = F.leaky_relu(self.batch_17(self.conv_17(layer_31)),leaky_relu_value,True)\n",
    "        layer_33 = F.leaky_relu(self.batch_18(self.conv_18(layer_32)),leaky_relu_value,True)\n",
    "        layer_34 = layer_31 + layer_33\n",
    "        layer_35 = F.leaky_relu(self.batch_17(self.conv_17(layer_34)),leaky_relu_value,True)\n",
    "        layer_36 = F.leaky_relu(self.batch_18(self.conv_18(layer_35)),leaky_relu_value,True)\n",
    "        layer_37 = layer_34 + layer_36\n",
    "        layer_38 = F.leaky_relu(self.batch_38(self.conv_38(layer_37)),leaky_relu_value,True)\n",
    "        layer_39 = F.leaky_relu(self.batch_39(self.conv_39(layer_38)),leaky_relu_value,True)\n",
    "        layer_40 = F.leaky_relu(self.batch_40(self.conv_40(layer_39)),leaky_relu_value,True)\n",
    "        layer_41 = layer_38 + layer_40\n",
    "        layer_42 = F.leaky_relu(self.batch_42(self.conv_42(layer_41)),leaky_relu_value,True)\n",
    "        layer_43 = F.leaky_relu(self.batch_43(self.conv_43(layer_42)),leaky_relu_value,True)\n",
    "        layer_44 = layer_41 + layer_43\n",
    "        layer_45 = F.leaky_relu(self.batch_42(self.conv_42(layer_44)),leaky_relu_value,True)\n",
    "        layer_46 = F.leaky_relu(self.batch_43(self.conv_43(layer_45)),leaky_relu_value,True)\n",
    "        layer_47 = layer_44 + layer_46\n",
    "        layer_48 = F.leaky_relu(self.batch_42(self.conv_42(layer_47)),leaky_relu_value,True)\n",
    "        layer_49 = F.leaky_relu(self.batch_43(self.conv_43(layer_48)),leaky_relu_value,True)\n",
    "        layer_50 = layer_47 + layer_49\n",
    "        layer_51 = F.leaky_relu(self.batch_42(self.conv_42(layer_50)),leaky_relu_value,True)\n",
    "        layer_52 = F.leaky_relu(self.batch_43(self.conv_43(layer_51)),leaky_relu_value,True)\n",
    "        layer_53 = layer_50 + layer_52\n",
    "        layer_54 = F.leaky_relu(self.batch_42(self.conv_42(layer_53)),leaky_relu_value,True)\n",
    "        layer_55 = F.leaky_relu(self.batch_43(self.conv_43(layer_54)),leaky_relu_value,True)\n",
    "        layer_56 = layer_53 +layer_55\n",
    "        layer_57 = F.leaky_relu(self.batch_42(self.conv_42(layer_56)),leaky_relu_value,True)\n",
    "        layer_58 = F.leaky_relu(self.batch_43(self.conv_43(layer_57)),leaky_relu_value,True)\n",
    "        layer_59 = layer_56 + layer_58\n",
    "        layer_60 = F.leaky_relu(self.batch_42(self.conv_42(layer_59)),leaky_relu_value,True)\n",
    "        layer_61 = F.leaky_relu(self.batch_43(self.conv_43(layer_60)),leaky_relu_value,True)\n",
    "        layer_62 = layer_59 + layer_61\n",
    "        layer_63 = F.leaky_relu(self.batch_63(self.conv_63(layer_62)),leaky_relu_value,True)\n",
    "        layer_64 = F.leaky_relu(self.batch_64(self.conv_64(layer_63)),leaky_relu_value,True)\n",
    "        layer_65 = F.leaky_relu(self.batch_65(self.conv_65(layer_64)),leaky_relu_value,True)\n",
    "        layer_66 = layer_63 + layer_65\n",
    "        layer_67 = F.leaky_relu(self.batch_67(self.conv_67(layer_66)),leaky_relu_value,True)\n",
    "        layer_68 = F.leaky_relu(self.batch_68(self.conv_68(layer_67)),leaky_relu_value,True)\n",
    "        layer_69 = layer_66 + layer_68\n",
    "        layer_70 = F.leaky_relu(self.batch_67(self.conv_67(layer_69)),leaky_relu_value,True)\n",
    "        layer_71 = F.leaky_relu(self.batch_68(self.conv_68(layer_70)),leaky_relu_value,True)\n",
    "        layer_72 = layer_69 + layer_71\n",
    "        layer_73 = F.leaky_relu(self.batch_67(self.conv_67(layer_72)),leaky_relu_value,True)\n",
    "        layer_74 = F.leaky_relu(self.batch_68(self.conv_68(layer_73)),leaky_relu_value,True)\n",
    "        layer_75 = layer_72 + layer_74\n",
    "        layer_76 = F.leaky_relu(self.batch_76(self.conv_76(layer_75)),leaky_relu_value,True)\n",
    "        layer_77 = F.leaky_relu(self.batch_77(self.conv_77(layer_76)),leaky_relu_value,True)\n",
    "        layer_78 = F.leaky_relu(self.batch_76(self.conv_76(layer_77)),leaky_relu_value,True)\n",
    "        layer_79 = F.leaky_relu(self.batch_77(self.conv_77(layer_78)),leaky_relu_value,True)\n",
    "        layer_80 = F.leaky_relu(self.batch_76(self.conv_76(layer_79)),leaky_relu_value,True)\n",
    "        layer_81 = F.leaky_relu(self.batch_77(self.conv_77(layer_80)),leaky_relu_value,True)\n",
    "        layer_82 = self.conv_82(layer_81)\n",
    "        layer_83 = layer_82\n",
    "        layer_84 = layer_80   # 16x16\n",
    "        layer_85 = F.leaky_relu(self.batch_85(self.conv_85(layer_84)),leaky_relu_value,True)\n",
    "        layer_86 = F.leaky_relu(self.batch_86(self.convT_86(layer_85)),leaky_relu_value,True)\n",
    "        layer_87 = torch.cat((layer_60,layer_86),1)\n",
    "        layer_88 = F.leaky_relu(self.batch_88(self.conv_88(layer_87)),leaky_relu_value,True)\n",
    "        layer_89 = F.leaky_relu(self.batch_89(self.conv_89(layer_88)),leaky_relu_value,True)\n",
    "        layer_90 = F.leaky_relu(self.batch_88(self.conv_88(layer_89)),leaky_relu_value,True)\n",
    "        layer_91 = F.leaky_relu(self.batch_89(self.conv_89(layer_90)),leaky_relu_value,True)\n",
    "        layer_92 = F.leaky_relu(self.batch_88(self.conv_88(layer_91)),leaky_relu_value,True)\n",
    "        layer_93 = F.leaky_relu(self.batch_89(self.conv_89(layer_92)),leaky_relu_value,True)\n",
    "        layer_94 = self.conv_94(layer_93)\n",
    "        layer_95 = layer_94\n",
    "        layer_96 = layer_92   # 32x32\n",
    "        layer_97 = F.leaky_relu(self.batch_97(self.conv_97(layer_96)),leaky_relu_value,True)\n",
    "        layer_98 = F.leaky_relu(self.batch_98(self.convT_98(layer_97)),leaky_relu_value,True)\n",
    "        layer_99 = torch.cat((layer_35,layer_98),1)\n",
    "        layer_100 = F.leaky_relu(self.batch_100(self.conv_100(layer_99)),leaky_relu_value,True)\n",
    "        layer_101 = F.leaky_relu(self.batch_101(self.conv_101(layer_100)),leaky_relu_value,True)\n",
    "        layer_102 = F.leaky_relu(self.batch_100(self.conv_100(layer_101)),leaky_relu_value,True)\n",
    "        layer_103 = F.leaky_relu(self.batch_101(self.conv_101(layer_102)),leaky_relu_value,True)\n",
    "        layer_104 = F.leaky_relu(self.batch_100(self.conv_100(layer_103)),leaky_relu_value,True)\n",
    "        layer_105 = F.leaky_relu(self.batch_101(self.conv_101(layer_104)),leaky_relu_value,True)\n",
    "        layer_106 = self.conv_106(layer_105)\n",
    "        layer_107 = layer_106   # 64x64\n",
    "        return layer_83, layer_95, layer_106   # ...*3*(5+26+10+4) = 135\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yolo_v3(\n",
      "  (conv_1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_7): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_10): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_13): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_14): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_15): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_17): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_18): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_38): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_39): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_39): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_40): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_42): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_42): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_43): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_63): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_63): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_64): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_65): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_65): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_67): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_68): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_68): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_76): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_76): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_77): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_77): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_82): Conv2d(1024, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_85): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_85): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (convT_86): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (batch_86): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_88): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_88): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_89): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_89): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_94): Conv2d(512, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_97): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_97): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (convT_98): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (batch_98): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_100): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_100): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_101): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_101): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_106): Conv2d(256, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Yolo_v3()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 135, 16, 16]) torch.Size([1, 135, 32, 32]) torch.Size([1, 135, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 512, 512)\n",
    "output_layer_1, output_layer_2, output_layer_3 = net(x)\n",
    "print(output_layer_1.size(),output_layer_2.size(),output_layer_3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer_dim(output_layer):\n",
    "    batch_number, outputs, y, x = output_layer.shape\n",
    "    return output_layer_1.view(batch_number, anchor_number, 5, outputs/5/anchor_number, y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 9, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(output_layer_dim(output_layer_1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: yolo_filter_boxes\n",
    "\n",
    "def yolo_filter_boxes(output_layer, ignore_thresh  = 0.7):\n",
    "    \"\"\"Filters YOLO boxes by thresholding on object and class confidence.\n",
    "    \n",
    "    Arguments:\n",
    "    box_confidence -- tensor of shape (19, 19, 5, 1)   (1,anchor_number,1,y,x)\n",
    "    boxes -- tensor of shape (19, 19, 5, 4)   (1,anchor_number,4,y,x)\n",
    "    box_class_probs -- tensor of shape (19, 19, 5, 80)   (1,anchor_number,classes,y,x)\n",
    "    threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None,), containing the class probability score for selected boxes\n",
    "    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes\n",
    "    classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes\n",
    "    \n",
    "    Note: \"None\" is here because you don't know the exact number of selected boxes, as it depends on the threshold. \n",
    "    For example, the actual output size of scores would be (10,) if there are 10 boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    box_confidence = output_layer\n",
    "    box_confidence[:,:,0<ingore_tresh,:,:] = 0\n",
    "    \n",
    "    # Step 1: Compute box scores\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    box_scores = box_confidence[:,:,0,:,:,:] * box_class_probs[:,:,:,:,:,:] # 19x19x80   1,3,1,x,y * 1,3,\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 2: Find the box_classes thanks to the max box_scores, keep track of the corresponding score\n",
    "    ### START CODE HERE ### (≈ 2 lines)\n",
    "    box_classes = K.argmax(box_scores, axis = -1)  # 19x19x5x1  (1 class index)\n",
    "    box_class_scores = K.max(box_scores, axis = -1)  # 19x19x5x1 (1 class score)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 3: Create a filtering mask based on \"box_class_scores\" by using \"threshold\". The mask should have the\n",
    "    # same dimension as box_class_scores, and be True for the boxes you want to keep (with probability >= threshold)\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    filtering_mask = box_class_scores >= threshold\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 4: Apply the mask to scores, boxes and classes\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24])\n",
      "tensor([[-0.0648,  0.7843,  0.1301, -0.4658,  0.1693,  0.8792,  1.3256,\n",
      "         -0.2433, -0.1955, -1.3749,  1.2619,  0.1159,  0.9152, -1.4587,\n",
      "          0.2737, -0.5083,  1.0659, -1.1094,  0.9076,  1.1037, -0.3661,\n",
      "         -0.5086, -1.0312, -0.7361]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,24)\n",
    "print(a.size())\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 8])\n",
      "tensor([[[-0.0648,  0.7843,  0.1301, -0.4658,  0.1693,  0.8792,  1.3256,\n",
      "          -0.2433],\n",
      "         [-0.1955, -1.3749,  1.2619,  0.1159,  0.9152, -1.4587,  0.2737,\n",
      "          -0.5083],\n",
      "         [ 1.0659, -1.1094,  0.9076,  1.1037, -0.3661, -0.5086, -1.0312,\n",
      "          -0.7361]]])\n"
     ]
    }
   ],
   "source": [
    "b = a.view(1,3,8)\n",
    "print(b.size())\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([1, 1, 12, 12])\n",
      "b:  torch.Size([1, 1, 6, 6])\n",
      "c:  torch.Size([1, 1, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,1,12,12)\n",
    "conv = nn.Conv2d(1,1,3, stride=2,padding=1)\n",
    "convT = nn.ConvTranspose2d(1,1,3,stride=2,padding=0)\n",
    "\n",
    "b = conv(a)\n",
    "c = convT(b)\n",
    "\n",
    "print(\"a: \", a.size())\n",
    "print(\"b: \", b.size())\n",
    "print(\"c: \", c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d:  torch.Size([1, 1, 6, 6])\n",
      "ConvTranspose2d:  torch.Size([1, 1, 24, 24])\n",
      "Conv2d und ConvTranspose2d:  torch.Size([1, 1, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1, 1, 12, 12)   # Batch, Anzahl channels, X,Y \n",
    "downsample = nn.Conv2d(1, 1, 3, stride=2, padding=1)\n",
    "upsample = nn.ConvTranspose2d(1, 1, 3, stride=2, padding=1,output_padding=1)\n",
    "h = downsample(inputs)\n",
    "print('Conv2d: ', h.size())        # (1, 1, 6, 6)\n",
    "output = upsample(inputs)\n",
    "print('ConvTranspose2d: ', output.size())    # (1, 1, 12, 12)\n",
    "g = upsample(h)\n",
    "print('Conv2d und ConvTranspose2d: ', g.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 16, 16])\n",
      "torch.Size([1, 3, 40, 16, 16])\n",
      "torch.Size([1, 3, 40, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,45,16,16)\n",
    "b = torch.randn(1,3,45,16,16)\n",
    "a_1 = a[:,:,0:1,:,:]\n",
    "b_1 = b[:,:,5:45,:,:]\n",
    "print(a_1.size())\n",
    "print(b_1.size())\n",
    "c = a_1 * b_1\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 8.5924e-02,  8.3530e-02, -1.2855e+00,  ...,\n",
      "            -2.2983e+00,  6.4186e-01, -5.4955e-01],\n",
      "           [-6.8604e-01, -5.5894e-01, -1.2368e+00,  ...,\n",
      "            -1.2608e+00,  1.0521e-01, -8.1081e-01],\n",
      "           [ 1.8457e+00, -2.6691e-01, -3.2460e+00,  ...,\n",
      "            -6.6300e-01, -5.1215e-01, -9.1043e-01],\n",
      "           ...,\n",
      "           [ 1.4533e-01,  9.4588e-01, -4.2047e-01,  ...,\n",
      "             2.2846e-01, -4.2947e-01, -6.0993e-01],\n",
      "           [ 9.2565e-01, -1.3237e+00,  8.6945e-01,  ...,\n",
      "             5.9381e-01,  1.8551e-01,  9.7864e-01],\n",
      "           [-2.6227e+00, -3.3103e-01, -8.1745e-02,  ...,\n",
      "             1.1209e+00, -9.1049e-01, -1.4109e+00]],\n",
      "\n",
      "          [[ 2.1742e+00,  3.1710e-01, -1.0947e+00,  ...,\n",
      "             1.8578e-02,  1.1656e+00, -1.3065e+00],\n",
      "           [ 2.3732e-01, -4.8158e-01,  7.0576e-01,  ...,\n",
      "            -1.2207e-02,  7.5089e-01, -5.8287e-01],\n",
      "           [ 4.3526e-02, -3.9022e-02,  8.5286e-01,  ...,\n",
      "            -9.7933e-01, -1.6753e-02,  3.4128e-01],\n",
      "           ...,\n",
      "           [ 7.9291e-01, -3.4019e-01, -1.3448e+00,  ...,\n",
      "             4.1798e-01, -2.2026e-01,  2.6167e-01],\n",
      "           [-8.8003e-01, -6.0296e-01,  9.2869e-01,  ...,\n",
      "             4.3354e-01, -4.7549e-01,  2.1340e-01],\n",
      "           [ 1.1576e-01, -4.5134e-01,  2.7948e-01,  ...,\n",
      "            -1.8411e+00,  1.7888e-01, -8.3475e-01]],\n",
      "\n",
      "          [[-2.0394e+00,  8.3937e-03,  1.5503e+00,  ...,\n",
      "             3.4009e-02,  8.3494e-01,  3.0715e-03],\n",
      "           [ 1.2023e+00, -3.0868e-01,  4.4577e-01,  ...,\n",
      "             1.3355e-01, -3.0685e-01,  1.7252e-01],\n",
      "           [ 2.5113e-01, -2.2166e-01, -1.6034e+00,  ...,\n",
      "            -2.5890e-01, -4.1655e-02,  2.0631e+00],\n",
      "           ...,\n",
      "           [ 3.4243e-01,  3.0142e+00,  1.9122e+00,  ...,\n",
      "            -1.0322e+00,  1.9254e+00, -2.8910e-01],\n",
      "           [ 4.3488e-01,  1.3638e-01, -1.6445e+00,  ...,\n",
      "             9.5988e-01,  5.2169e-01,  2.9684e-01],\n",
      "           [ 7.8516e-01,  6.6373e-01,  7.8670e-01,  ...,\n",
      "             3.5584e-01, -1.9953e+00,  1.6248e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.6214e+00,  4.2137e-01,  5.0498e-01,  ...,\n",
      "            -4.3570e-01, -1.9642e+00,  8.9134e-01],\n",
      "           [-7.3379e-01, -1.5701e-01, -9.1046e-01,  ...,\n",
      "            -1.9851e+00, -4.3855e-02, -1.1876e-01],\n",
      "           [-1.6120e+00, -7.1604e-02, -4.0727e-01,  ...,\n",
      "            -1.5595e+00,  4.8595e-01, -6.7943e-02],\n",
      "           ...,\n",
      "           [-6.9524e-01,  1.0106e-01, -2.3749e+00,  ...,\n",
      "             1.5133e-01, -1.9397e+00,  2.7978e-01],\n",
      "           [ 3.3927e+00,  2.0896e+00,  1.7167e+00,  ...,\n",
      "            -4.6117e-01,  5.4320e-01, -2.7531e-02],\n",
      "           [ 1.4997e+00,  3.7767e-02,  2.7066e-01,  ...,\n",
      "             2.2832e-01, -5.6362e-01, -7.7819e-01]],\n",
      "\n",
      "          [[-1.3539e-01,  4.7200e-01, -3.1995e-01,  ...,\n",
      "            -4.4722e-01,  1.0786e+00, -5.2343e-01],\n",
      "           [-3.4697e-01,  1.3075e+00, -8.9617e-01,  ...,\n",
      "             3.0938e-01, -1.7165e+00,  1.0699e+00],\n",
      "           [ 4.8302e-01,  3.4529e-02, -9.1548e-01,  ...,\n",
      "             6.4836e-01,  1.5941e+00,  3.7501e-01],\n",
      "           ...,\n",
      "           [ 2.0547e+00,  1.5671e+00,  1.4971e+00,  ...,\n",
      "             2.8959e-01,  1.0904e+00,  1.3388e+00],\n",
      "           [-1.0694e+00,  2.0638e+00,  8.7219e-01,  ...,\n",
      "             8.6042e-02,  2.3101e+00, -9.7132e-01],\n",
      "           [-1.0379e+00,  2.5817e+00, -1.0477e-02,  ...,\n",
      "             2.1131e-01,  1.4037e+00, -5.5003e-01]],\n",
      "\n",
      "          [[-2.3889e+00,  8.1309e-02,  6.8038e-01,  ...,\n",
      "            -8.5056e-01,  4.3056e-01, -7.3310e-01],\n",
      "           [-9.7028e-01, -1.7331e+00, -1.2973e+00,  ...,\n",
      "            -5.8019e-01, -1.8463e-02,  6.9773e-02],\n",
      "           [-1.8625e+00,  1.2272e+00,  1.1762e+00,  ...,\n",
      "            -1.6257e-01,  1.6873e+00, -1.0755e+00],\n",
      "           ...,\n",
      "           [ 9.7097e-01, -1.3363e+00,  1.1255e+00,  ...,\n",
      "             2.3859e-01, -1.1817e+00, -3.4528e-01],\n",
      "           [ 3.1197e-01,  1.1107e-01, -3.3137e-01,  ...,\n",
      "            -3.0075e-01, -1.3619e-01,  3.8995e-01],\n",
      "           [ 4.9175e-01, -1.0517e+00, -1.3502e+00,  ...,\n",
      "             3.4244e-01,  5.6623e-02,  2.6555e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 6.6734e-01,  2.7977e-01,  7.6439e-01,  ...,\n",
      "            -4.6208e-02,  4.3453e-01, -1.7228e+00],\n",
      "           [-2.5923e-01, -1.2365e+00, -4.7779e-01,  ...,\n",
      "             7.8678e-01,  1.3149e+00,  2.1172e-01],\n",
      "           [-3.1138e-01, -5.6531e-01,  4.7946e-01,  ...,\n",
      "             1.3762e+00, -2.6003e-01,  3.7987e-01],\n",
      "           ...,\n",
      "           [-5.3820e-01,  4.6093e-03, -6.9443e-01,  ...,\n",
      "            -1.0754e+00,  7.0503e-02, -2.0603e+00],\n",
      "           [-1.2984e+00,  3.8138e-01,  7.0920e-01,  ...,\n",
      "             3.9690e-01, -4.1601e-01,  1.2766e+00],\n",
      "           [ 9.7117e-02,  1.9030e+00, -1.1365e+00,  ...,\n",
      "             5.8967e-01, -8.9472e-02, -1.4487e+00]],\n",
      "\n",
      "          [[-2.1365e+00, -7.1623e-01, -2.1551e-01,  ...,\n",
      "            -1.8447e-01, -1.0373e+00,  4.4660e-01],\n",
      "           [-7.8078e-01,  6.6088e-01, -1.5725e-01,  ...,\n",
      "            -3.4998e-01,  4.4188e-01,  5.2711e-01],\n",
      "           [ 1.1944e+00,  1.0705e+00,  1.0161e+00,  ...,\n",
      "            -2.7364e+00, -5.7308e-01, -4.6426e-01],\n",
      "           ...,\n",
      "           [-1.3690e+00, -9.4842e-02,  1.4996e-01,  ...,\n",
      "             1.5398e+00, -5.9910e-01,  1.2416e-01],\n",
      "           [ 2.3338e-01,  4.3824e-01, -9.4022e-01,  ...,\n",
      "             2.6005e-01,  9.3757e-01, -2.0473e+00],\n",
      "           [-3.7602e-01,  4.0371e-01,  4.6933e-01,  ...,\n",
      "             1.2201e+00, -1.8377e+00, -2.4080e+00]],\n",
      "\n",
      "          [[-1.1002e+00,  5.1068e-01,  8.1797e-02,  ...,\n",
      "            -2.2005e-01, -5.7026e-01, -7.3925e-03],\n",
      "           [-4.3049e-01, -1.9788e-01,  6.7966e-01,  ...,\n",
      "             9.4327e-01,  1.4038e+00, -8.7331e-01],\n",
      "           [-1.2065e+00,  1.2081e+00, -2.1873e+00,  ...,\n",
      "            -1.3140e+00, -1.3101e+00, -4.0805e-01],\n",
      "           ...,\n",
      "           [-6.8404e-01,  7.8448e-01, -1.2080e+00,  ...,\n",
      "             4.0354e-01,  1.7786e-01,  3.2142e-01],\n",
      "           [ 1.5567e-01,  1.0612e+00, -1.4509e-02,  ...,\n",
      "             1.6343e+00, -3.1074e-02, -9.3452e-01],\n",
      "           [ 1.0786e+00, -1.1856e+00, -1.1874e+00,  ...,\n",
      "            -8.0300e-01,  2.5269e-01, -4.9460e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 2.2845e-01, -6.7472e-01, -3.3450e-01,  ...,\n",
      "             1.1690e+00, -1.5070e+00, -1.3732e+00],\n",
      "           [-5.9441e-01,  4.9301e-01,  4.2133e-01,  ...,\n",
      "             9.0335e-02, -1.5219e-01,  1.2957e+00],\n",
      "           [-4.8394e-01, -6.9734e-01,  3.4662e-01,  ...,\n",
      "             7.8741e-01, -8.5789e-01, -3.7434e-01],\n",
      "           ...,\n",
      "           [ 2.0737e+00,  8.1051e-01,  6.9249e-01,  ...,\n",
      "             5.6261e-01, -1.3595e+00,  5.3334e-01],\n",
      "           [-1.4200e-01,  1.5465e-01,  2.8118e-01,  ...,\n",
      "             2.5943e-01, -1.1405e+00, -7.1775e-01],\n",
      "           [ 1.4709e-01,  5.9735e-01, -8.9154e-01,  ...,\n",
      "             3.1825e-01,  5.6489e-01,  1.2260e+00]],\n",
      "\n",
      "          [[-9.7585e-01, -3.6159e-01, -4.8480e-01,  ...,\n",
      "             9.7581e-01, -1.5951e-02,  1.1516e+00],\n",
      "           [ 3.5000e-01,  1.1553e+00,  1.1060e+00,  ...,\n",
      "             3.2180e-01, -1.5103e+00,  8.6136e-01],\n",
      "           [ 5.3999e-01, -8.9655e-02, -1.0816e+00,  ...,\n",
      "            -1.2471e-01,  1.2524e+00,  1.5349e+00],\n",
      "           ...,\n",
      "           [ 6.0967e-01, -1.4215e+00, -2.3108e-01,  ...,\n",
      "             6.6832e-01,  6.9048e-01, -2.9308e-01],\n",
      "           [-1.9020e+00,  6.8329e-01,  6.8504e-01,  ...,\n",
      "             1.1565e+00,  9.3317e-01, -2.3842e+00],\n",
      "           [-4.2681e-01,  6.6319e-01,  1.1587e+00,  ...,\n",
      "            -1.6013e+00, -1.8650e-01, -3.2270e-01]],\n",
      "\n",
      "          [[-8.4742e-01, -5.7487e-01, -5.4218e-01,  ...,\n",
      "            -5.6562e-01,  1.3613e-01,  1.0367e+00],\n",
      "           [ 4.5010e-01,  6.3063e-01,  2.6115e-01,  ...,\n",
      "            -1.0986e+00,  6.4992e-01, -1.4252e+00],\n",
      "           [ 7.6587e-01,  5.7374e-01,  4.3743e-01,  ...,\n",
      "             9.9109e-01,  3.5852e-01, -5.7297e-01],\n",
      "           ...,\n",
      "           [ 1.4776e+00, -8.2550e-01,  2.1378e-01,  ...,\n",
      "            -4.9423e-01, -1.1866e+00, -6.7032e-01],\n",
      "           [ 1.1730e+00, -1.3942e+00,  2.4001e-01,  ...,\n",
      "             5.4752e-03,  1.5187e+00, -7.6309e-02],\n",
      "           [-1.1049e+00,  8.1628e-01, -4.2168e-01,  ...,\n",
      "             1.0097e+00,  2.0336e-01, -6.4889e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1383e+00,  4.9424e-01, -2.0522e+00,  ...,\n",
      "             1.3938e+00, -1.1308e+00,  1.2630e+00],\n",
      "           [ 1.9486e-01,  7.1103e-01, -1.7222e+00,  ...,\n",
      "            -1.2584e+00,  7.2882e-01,  6.1558e-01],\n",
      "           [-4.4246e-01,  3.2939e-01, -9.5812e-01,  ...,\n",
      "             2.8624e-01, -1.0101e+00, -1.1005e-01],\n",
      "           ...,\n",
      "           [ 1.1029e+00, -5.6674e-01,  1.4747e+00,  ...,\n",
      "             6.4082e-01, -2.5067e-01, -2.1325e-01],\n",
      "           [-4.7468e-01,  7.8083e-01, -1.0871e+00,  ...,\n",
      "             6.3102e-01,  1.6227e-01, -1.0836e-01],\n",
      "           [ 9.9006e-01, -5.5118e-01, -1.5400e+00,  ...,\n",
      "             1.0150e+00,  6.7790e-01, -8.2481e-01]],\n",
      "\n",
      "          [[-7.2623e-01, -4.3943e-01, -2.7461e-01,  ...,\n",
      "            -7.3141e-01,  1.4146e+00,  3.7986e-01],\n",
      "           [-5.3371e-01, -1.1908e+00, -1.3987e-01,  ...,\n",
      "             1.2614e+00, -5.9057e-01,  5.4220e-01],\n",
      "           [ 7.2163e-02,  5.0400e-01,  1.1585e-01,  ...,\n",
      "             2.1770e-01, -1.1926e-01,  6.0990e-01],\n",
      "           ...,\n",
      "           [-1.1164e+00, -6.0528e-01, -9.2436e-01,  ...,\n",
      "             7.7399e-01,  2.9471e-01,  3.3049e-03],\n",
      "           [ 4.8819e-02, -1.6135e+00, -1.5668e+00,  ...,\n",
      "            -3.3704e-01,  2.2127e-02, -3.4019e-01],\n",
      "           [ 8.7001e-01,  1.0049e+00,  1.1375e-01,  ...,\n",
      "             1.0294e+00,  4.3790e-02,  1.5926e-01]],\n",
      "\n",
      "          [[-7.9127e-01, -5.0714e-01,  1.5576e+00,  ...,\n",
      "            -1.2895e+00,  2.4865e-01,  6.0855e-01],\n",
      "           [-2.4142e-01, -1.2298e-01,  1.2645e+00,  ...,\n",
      "            -7.8210e-01,  5.9785e-01, -8.2536e-01],\n",
      "           [-2.9513e-01, -1.7944e-01,  1.1465e+00,  ...,\n",
      "            -5.7871e-01, -2.5312e+00,  1.1589e+00],\n",
      "           ...,\n",
      "           [-1.1184e+00,  2.2705e+00,  1.3006e-01,  ...,\n",
      "            -1.4395e+00, -6.5145e-01, -2.0707e-01],\n",
      "           [-1.3474e+00, -8.6302e-02,  6.2115e-01,  ...,\n",
      "            -1.0652e+00,  1.0302e+00,  4.4141e-01],\n",
      "           [-1.2540e+00,  2.7439e-01, -4.8671e-01,  ...,\n",
      "            -1.0200e+00, -2.0616e-01, -2.1665e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 5.9571e-01,  1.3876e+00,  9.2159e-01,  ...,\n",
      "             7.3721e-01, -1.2524e+00,  1.6465e+00],\n",
      "           [ 3.8882e-01,  1.3278e-01, -1.4054e+00,  ...,\n",
      "             9.0857e-01,  9.9297e-02, -7.7999e-01],\n",
      "           [ 7.2621e-01,  2.4728e+00,  2.5946e-01,  ...,\n",
      "            -7.1078e-01,  3.7027e-01,  4.3910e-01],\n",
      "           ...,\n",
      "           [ 8.0188e-01,  1.3653e+00,  6.1181e-01,  ...,\n",
      "             6.8167e-01,  1.9330e+00,  5.8978e-01],\n",
      "           [ 7.0700e-01,  4.4199e-01, -2.4874e-01,  ...,\n",
      "             2.3499e-01,  3.6318e-02, -4.2858e-01],\n",
      "           [-7.2069e-01, -7.2761e-01, -5.7710e-01,  ...,\n",
      "             1.0016e+00, -7.9140e-01,  1.9401e-01]],\n",
      "\n",
      "          [[ 2.5893e-01,  7.4945e-01, -9.8694e-01,  ...,\n",
      "             1.0930e+00,  2.1244e+00,  1.1144e+00],\n",
      "           [ 6.0627e-01, -1.1321e+00,  3.0036e-01,  ...,\n",
      "             4.3910e-01, -4.2740e-01, -3.2592e-01],\n",
      "           [ 1.9562e-01,  2.1459e+00,  4.1779e-01,  ...,\n",
      "            -2.6874e-01,  7.3667e-01, -8.0325e-02],\n",
      "           ...,\n",
      "           [-6.7879e-01, -4.3214e-01, -5.1136e-01,  ...,\n",
      "            -3.8481e-01,  7.8109e-01, -1.0172e+00],\n",
      "           [ 2.8433e-01,  2.9015e-01,  1.7138e+00,  ...,\n",
      "             3.0367e-02, -4.8653e-01, -5.1472e-02],\n",
      "           [-9.9311e-01,  6.5931e-01,  9.3301e-01,  ...,\n",
      "            -5.9505e-01,  3.2643e-01, -8.6746e-02]],\n",
      "\n",
      "          [[-3.4944e-01,  3.0063e-01,  1.9599e+00,  ...,\n",
      "            -3.1786e-01, -4.5796e-01,  1.0136e-01],\n",
      "           [ 3.1845e-01,  8.5808e-01, -1.1728e+00,  ...,\n",
      "            -5.6829e-01,  9.6128e-01,  2.3766e+00],\n",
      "           [ 2.7024e-01,  3.7921e-01,  4.6360e-01,  ...,\n",
      "             5.7057e-03,  9.7710e-02,  1.6991e-01],\n",
      "           ...,\n",
      "           [ 9.0590e-01, -6.0759e-01,  2.2761e+00,  ...,\n",
      "             7.1229e-01, -7.9114e-01, -8.9544e-01],\n",
      "           [-1.5953e+00, -1.0828e+00,  9.3744e-01,  ...,\n",
      "            -1.0458e+00,  5.2504e-01,  8.1541e-01],\n",
      "           [-5.6847e-01,  4.7732e-01,  9.0946e-01,  ...,\n",
      "            -4.0380e-01, -1.5934e+00, -4.5868e-01]]]]])\n",
      "tensor([[[[[-6.3441e-02, -3.4911e-02,  2.1193e-01,  ...,\n",
      "            -3.5142e+00, -3.4061e-01, -3.7387e-01],\n",
      "           [-1.3686e-01, -6.6026e-01,  2.4301e-01,  ...,\n",
      "             7.9134e-01, -4.9395e-03, -4.2218e-01],\n",
      "           [-6.6977e-01, -1.9239e-01,  1.7794e+00,  ...,\n",
      "             6.5935e-01,  6.1509e-01,  1.7327e-01],\n",
      "           ...,\n",
      "           [ 3.6272e-02,  1.3192e-01, -3.4681e-01,  ...,\n",
      "            -8.2762e-02, -2.3224e-01, -1.3462e+00],\n",
      "           [ 1.1090e+00, -4.9261e-01, -1.3450e-01,  ...,\n",
      "             3.1712e-01, -1.4792e-02,  6.8708e-01],\n",
      "           [ 1.3691e+00, -5.1617e-01, -2.6213e-02,  ...,\n",
      "            -5.6305e-01,  6.0266e-02,  2.3185e+00]],\n",
      "\n",
      "          [[ 2.0379e-02,  5.7095e-02, -4.0005e-01,  ...,\n",
      "             1.1159e+00, -6.8137e-01,  6.1702e-01],\n",
      "           [-3.9621e-01,  3.9973e-01,  1.3002e+00,  ...,\n",
      "             6.0480e-01,  9.1614e-02, -5.8656e-02],\n",
      "           [-1.6750e+00,  9.1241e-02,  1.8760e+00,  ...,\n",
      "             4.4607e-01, -3.6350e-01, -1.1264e+00],\n",
      "           ...,\n",
      "           [ 2.2338e-01,  1.2599e+00, -8.0171e-01,  ...,\n",
      "             1.0376e-01,  5.0288e-01, -6.4071e-02],\n",
      "           [ 2.2434e-01,  7.4229e-01, -1.3317e+00,  ...,\n",
      "            -1.6904e+00,  1.8362e-01, -1.1951e-01],\n",
      "           [-1.6573e+00,  6.2331e-01, -2.7403e-03,  ...,\n",
      "            -7.8253e-01,  1.1584e+00, -4.3807e-01]],\n",
      "\n",
      "          [[-1.4491e-01,  1.9109e-01,  4.1789e-01,  ...,\n",
      "            -2.4904e+00, -7.1769e-01, -1.7738e-01],\n",
      "           [-4.5338e-02,  6.7482e-01, -1.1603e+00,  ...,\n",
      "            -4.9295e-01, -2.9782e-01,  2.4058e-01],\n",
      "           [-2.6604e-02,  2.9884e-02, -3.1676e+00,  ...,\n",
      "            -1.1353e+00,  1.5455e-01, -2.7589e-01],\n",
      "           ...,\n",
      "           [-5.9164e-02,  1.3234e+00, -6.2490e-01,  ...,\n",
      "             7.9163e-02,  3.8520e-01, -4.0597e-01],\n",
      "           [-3.2539e-01, -1.9308e+00, -1.1071e+00,  ...,\n",
      "             3.6001e-01,  2.6231e-01, -6.9770e-01],\n",
      "           [-2.0311e+00, -2.5204e-01, -9.6543e-04,  ...,\n",
      "            -7.9729e-01, -3.3421e-01,  1.7740e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 4.5619e-03,  3.5610e-03,  1.6434e+00,  ...,\n",
      "            -3.0553e+00, -6.5168e-01,  1.3986e-01],\n",
      "           [-1.6359e-01,  7.4670e-02,  5.8828e-01,  ...,\n",
      "             9.0850e-01,  2.0172e-01, -1.8957e+00],\n",
      "           [-1.4143e+00, -4.1447e-01,  8.2569e+00,  ...,\n",
      "             5.0811e-01,  2.5728e-01, -1.7884e-01],\n",
      "           ...,\n",
      "           [-2.9110e-01,  8.2393e-01,  2.4360e-01,  ...,\n",
      "            -3.2803e-01, -5.3725e-01,  3.1434e-01],\n",
      "           [ 1.0550e+00,  1.2270e+00,  1.8635e-01,  ...,\n",
      "            -3.0270e-01, -8.4413e-02, -2.0255e+00],\n",
      "           [ 2.0542e+00, -3.1937e-01,  3.9274e-02,  ...,\n",
      "            -1.0715e+00, -7.4190e-01, -1.3313e+00]],\n",
      "\n",
      "          [[ 1.5778e-01,  1.3353e-01,  1.3033e+00,  ...,\n",
      "            -2.4606e+00, -4.3767e-01,  1.7692e-01],\n",
      "           [ 8.0674e-01,  9.0432e-01,  1.6186e+00,  ...,\n",
      "             2.9382e-01,  5.9268e-02,  4.1132e-01],\n",
      "           [ 1.1936e+00,  3.5065e-01,  7.5362e+00,  ...,\n",
      "            -1.3779e+00, -1.0881e+00,  1.0863e-01],\n",
      "           ...,\n",
      "           [ 6.8357e-02, -4.2928e-02,  4.9304e-02,  ...,\n",
      "            -7.0704e-01,  4.0770e-01,  9.7584e-02],\n",
      "           [-4.8137e-01,  8.5938e-02,  8.1177e-01,  ...,\n",
      "             1.1558e+00, -4.0369e-01, -5.9402e-01],\n",
      "           [ 9.8297e-01, -5.6102e-02, -1.6696e-02,  ...,\n",
      "            -8.4120e-01,  1.3431e+00, -5.2899e-01]],\n",
      "\n",
      "          [[-1.3701e-01,  5.6057e-02, -7.9450e-01,  ...,\n",
      "             2.7227e+00,  4.3730e-01,  4.7302e-01],\n",
      "           [ 4.0628e-01, -8.3452e-01,  2.0269e-01,  ...,\n",
      "             1.5203e+00, -1.2761e-01, -6.4450e-01],\n",
      "           [ 2.0788e+00, -2.4307e-01,  2.1156e+00,  ...,\n",
      "            -6.1852e-01, -5.9966e-02, -9.9447e-01],\n",
      "           ...,\n",
      "           [-3.1753e-02,  7.6139e-01, -4.2666e-01,  ...,\n",
      "            -9.1934e-02, -6.0749e-01,  7.4188e-01],\n",
      "           [-5.2734e-01,  3.4410e+00, -5.1149e-01,  ...,\n",
      "            -2.7451e-01,  1.5428e-01, -6.0487e-01],\n",
      "           [ 1.0595e+00,  1.4280e-01, -1.3785e-02,  ...,\n",
      "             1.8179e+00, -1.6537e+00,  2.2294e-01]]],\n",
      "\n",
      "\n",
      "         [[[-3.6386e-01,  3.1024e-01, -2.7648e-01,  ...,\n",
      "            -2.4048e-02,  1.2336e-01,  3.4190e-01],\n",
      "           [-2.4990e-01,  1.6377e-01, -3.1305e-01,  ...,\n",
      "            -9.1032e-01,  1.7328e+00,  1.2831e-01],\n",
      "           [-8.9755e-02, -5.1864e-01,  2.8759e-01,  ...,\n",
      "            -6.1607e-01,  4.3484e-01, -1.9837e-02],\n",
      "           ...,\n",
      "           [-9.8984e-01,  4.3891e-03, -3.1279e-01,  ...,\n",
      "             9.9206e-02, -9.4519e-02,  1.4484e+00],\n",
      "           [-1.0145e+00, -3.5177e-01, -1.3917e+00,  ...,\n",
      "             4.9067e-01, -2.4572e-01,  1.1784e-01],\n",
      "           [-1.0498e-01,  1.0239e+00, -1.5562e+00,  ...,\n",
      "            -8.3788e-01,  1.1737e-01, -9.4647e-01]],\n",
      "\n",
      "          [[-7.1045e-01,  2.1037e-02,  2.3247e+00,  ...,\n",
      "            -4.9075e-02,  4.9029e-01,  8.3323e-02],\n",
      "           [-2.1200e-02, -1.2414e-01,  9.2827e-02,  ...,\n",
      "            -5.5145e-01,  9.8119e-01, -1.7176e-01],\n",
      "           [-5.1630e-01, -5.7310e-01,  2.5797e-01,  ...,\n",
      "             3.2116e+00,  2.7186e-01,  1.3346e-01],\n",
      "           ...,\n",
      "           [-4.8220e-01,  1.1707e-04, -1.9292e-01,  ...,\n",
      "             1.4215e+00,  1.1810e-01, -5.0533e-01],\n",
      "           [-1.9228e-01,  1.0861e-01,  2.5218e+00,  ...,\n",
      "             8.4066e-01,  5.6478e-02,  2.9316e-01],\n",
      "           [ 1.6650e-01, -4.9058e-01,  2.1789e+00,  ...,\n",
      "            -1.7214e+00, -1.5452e-01,  3.0138e-01]],\n",
      "\n",
      "          [[-5.9137e-01,  4.9855e-02,  1.1312e+00,  ...,\n",
      "            -6.6671e-04,  3.8641e-01, -1.8937e+00],\n",
      "           [-9.2879e-02, -1.2902e+00, -1.4122e-02,  ...,\n",
      "            -4.2874e-01,  3.7484e-01, -1.1421e-02],\n",
      "           [-4.8132e-01,  1.0522e+00,  9.1988e-03,  ...,\n",
      "            -5.0911e-01, -2.2144e-01,  2.6482e-01],\n",
      "           ...,\n",
      "           [ 1.1530e-01, -4.0337e-04, -9.8727e-01,  ...,\n",
      "            -2.3441e+00, -1.1059e-01, -1.1842e+00],\n",
      "           [-2.0865e-01,  6.7538e-01,  3.4602e-01,  ...,\n",
      "             5.4650e-01, -6.2861e-01,  4.5854e-01],\n",
      "           [-2.5700e-02,  2.8175e+00,  1.1657e+00,  ...,\n",
      "             6.7055e-01,  9.7298e-03, -1.9537e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.8094e-01, -7.3369e-02,  3.6041e-02,  ...,\n",
      "            -3.0142e-02,  1.4151e-01,  7.1347e-01],\n",
      "           [-8.8244e-02,  5.7749e-01, -2.9155e-01,  ...,\n",
      "            -8.6174e-01,  7.8576e-01,  2.3577e-01],\n",
      "           [ 3.1060e-01, -1.4292e-01, -6.4051e-01,  ...,\n",
      "             1.2165e+00, -4.1374e-02, -2.1048e-01],\n",
      "           ...,\n",
      "           [-7.9094e-01, -5.3407e-03,  4.9889e-01,  ...,\n",
      "             1.0665e+00, -8.8585e-02, -1.6088e+00],\n",
      "           [-5.6682e-01,  4.6451e-01,  1.2224e+00,  ...,\n",
      "            -1.4262e-01,  2.1659e-01,  1.4666e+00],\n",
      "           [ 1.2842e-01,  3.1469e+00, -1.4247e-01,  ...,\n",
      "             7.2930e-01, -4.3269e-02,  7.9755e-01]],\n",
      "\n",
      "          [[-2.4423e-01,  9.6248e-02,  1.0795e-01,  ...,\n",
      "             4.6951e-02,  6.3861e-01, -3.3240e-01],\n",
      "           [-7.3812e-03, -3.5868e-01, -2.3729e-01,  ...,\n",
      "             1.9210e-01,  2.4344e+00,  6.8268e-03],\n",
      "           [ 3.2950e-01,  3.7974e-01, -1.4499e-02,  ...,\n",
      "             9.9227e-01, -3.6389e-01, -1.6607e-01],\n",
      "           ...,\n",
      "           [-5.4765e-02, -3.9950e-04,  2.8815e-01,  ...,\n",
      "            -9.3485e-01,  4.3522e-02, -4.0316e+00],\n",
      "           [ 2.6026e-01,  4.7536e-01,  1.3148e+00,  ...,\n",
      "            -6.8452e-01,  4.3880e-01, -2.7628e-02],\n",
      "           [-1.0359e-01,  1.3910e-01, -1.2644e+00,  ...,\n",
      "             6.1979e-02, -7.5917e-02,  1.3151e+00]],\n",
      "\n",
      "          [[ 4.6680e-01,  2.4433e-01,  4.6443e-01,  ...,\n",
      "             7.1333e-02,  5.2321e-01,  1.7981e+00],\n",
      "           [ 1.0919e-01,  1.2525e-01, -3.8586e-01,  ...,\n",
      "             6.7785e-01,  1.0607e+00,  1.8738e-01],\n",
      "           [-1.7254e-01, -3.0829e-01, -2.2766e-01,  ...,\n",
      "            -4.2420e-01,  1.7700e-01,  8.4106e-01],\n",
      "           ...,\n",
      "           [-1.7472e-01,  3.2337e-03,  1.0873e+00,  ...,\n",
      "             1.0150e+00, -4.9305e-02,  1.6783e+00],\n",
      "           [-6.2834e-01,  6.5510e-01, -4.3241e-01,  ...,\n",
      "            -1.5324e-01, -7.1206e-01,  9.0603e-01],\n",
      "           [-8.1978e-02, -4.6050e+00,  4.2253e-02,  ...,\n",
      "            -8.8044e-01,  4.9037e-03, -3.3945e+00]]],\n",
      "\n",
      "\n",
      "         [[[-1.0431e+00,  3.2266e-01,  1.2836e+00,  ...,\n",
      "             1.5409e+00, -2.2639e+00,  5.6606e-01],\n",
      "           [ 2.4791e-01, -4.3859e-01, -9.8659e-01,  ...,\n",
      "            -1.3264e+00, -5.1780e-01,  2.2621e-02],\n",
      "           [-2.6508e-01, -3.3238e-02, -4.1236e-01,  ...,\n",
      "             2.2513e-01,  1.9573e+00,  1.3247e-01],\n",
      "           ...,\n",
      "           [ 1.0683e+00,  1.0959e-01, -1.7275e+00,  ...,\n",
      "             2.7599e-01, -2.7747e-01, -1.0506e-01],\n",
      "           [-5.0151e-01, -5.4623e-01, -8.2799e-01,  ...,\n",
      "            -6.8665e-01,  2.7859e-02,  1.3295e-01],\n",
      "           [-1.5431e+00, -1.6014e-01, -3.0267e+00,  ...,\n",
      "            -1.0243e+00, -2.9022e-01,  6.9141e-01]],\n",
      "\n",
      "          [[-3.9340e-01, -9.2467e-01,  4.5744e-01,  ...,\n",
      "            -1.5597e+00,  1.1128e+00, -1.5629e+00],\n",
      "           [-8.7484e-02, -1.8985e+00, -4.0165e-01,  ...,\n",
      "             1.8454e+00, -4.8281e-01, -5.5910e-01],\n",
      "           [ 2.4932e-01,  2.3879e-01, -1.0165e+00,  ...,\n",
      "            -1.9484e-01,  6.2381e-01, -1.6475e-02],\n",
      "           ...,\n",
      "           [ 1.1533e+00,  6.1416e-01,  2.4113e+00,  ...,\n",
      "            -1.8729e-02,  1.6464e-01, -5.3409e-02],\n",
      "           [-5.8376e-03,  9.1170e-01,  2.3700e+00,  ...,\n",
      "             8.6810e-01, -1.0841e-01, -2.5901e-02],\n",
      "           [ 1.4681e+00, -4.4202e-01,  1.1195e-01,  ...,\n",
      "             1.7650e+00, -1.7400e+00, -9.3328e-01]],\n",
      "\n",
      "          [[ 1.0585e+00,  5.0069e-01,  1.8837e+00,  ...,\n",
      "            -9.1654e-01, -3.3851e-01, -7.5581e-01],\n",
      "           [ 1.5384e-01,  2.7245e-01, -2.3624e+00,  ...,\n",
      "             3.5031e+00, -1.0986e-01, -6.2281e-01],\n",
      "           [-3.9595e-01,  4.4074e-01,  2.7042e+00,  ...,\n",
      "            -2.0481e-02,  8.0175e-01,  1.7826e-01],\n",
      "           ...,\n",
      "           [ 1.5001e-01,  8.9986e-01,  3.1545e+00,  ...,\n",
      "             1.3374e+00, -3.0241e-01, -4.8441e-02],\n",
      "           [ 3.4827e-01, -3.6139e-01, -9.3149e-02,  ...,\n",
      "            -1.3333e+00,  4.4206e-02, -7.8790e-02],\n",
      "           [-2.8991e-01,  1.1621e-01, -2.2620e+00,  ...,\n",
      "             1.8038e+00,  8.1903e-01, -9.7100e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-7.7237e-01,  5.2757e-01,  2.2306e+00,  ...,\n",
      "             4.6746e-01, -5.3052e-02, -1.3031e-01],\n",
      "           [-8.1967e-02,  4.0880e-01,  4.6311e-01,  ...,\n",
      "            -3.7926e-01, -2.0046e-01, -8.6561e-02],\n",
      "           [-4.1287e-01, -4.7782e-01, -2.7888e-01,  ...,\n",
      "            -3.8861e-01, -1.5998e+00,  3.9725e-02],\n",
      "           ...,\n",
      "           [-1.5457e+00,  5.1320e-01,  7.4182e-01,  ...,\n",
      "            -3.4878e-02,  3.8037e-01, -3.3530e-02],\n",
      "           [-5.8536e-01,  8.4513e-01, -5.1530e-01,  ...,\n",
      "             6.1705e-01, -1.4699e-01, -7.3866e-02],\n",
      "           [-1.7828e-01, -2.9507e-01, -2.6274e+00,  ...,\n",
      "             3.3736e-01,  9.3604e-01, -2.1935e-01]],\n",
      "\n",
      "          [[ 6.9512e-01, -7.7457e-02, -1.4499e+00,  ...,\n",
      "            -1.2724e+00,  5.7665e-01, -3.9178e-02],\n",
      "           [ 7.1036e-02,  4.0511e-01, -1.3443e+00,  ...,\n",
      "            -3.7615e+00,  1.7705e-01, -6.2266e-01],\n",
      "           [-2.2352e-01,  4.0694e-01, -2.7685e-01,  ...,\n",
      "            -9.4870e-02, -4.9577e-01,  2.9133e-02],\n",
      "           ...,\n",
      "           [-1.1008e+00,  4.5443e-01, -2.3549e+00,  ...,\n",
      "            -5.5511e-01,  6.2818e-01,  1.3061e-01],\n",
      "           [ 1.5226e-02, -1.5388e-01,  3.6019e-01,  ...,\n",
      "             1.1148e+00, -1.1231e-01,  7.7147e-02],\n",
      "           [-2.5081e-03, -2.4336e-01, -1.1797e+00,  ...,\n",
      "            -1.7487e+00, -8.0351e-01, -9.4362e-01]],\n",
      "\n",
      "          [[-5.2194e-01, -5.4416e-01,  8.9187e-01,  ...,\n",
      "             1.9682e+00,  2.6044e+00, -7.2676e-01],\n",
      "           [ 1.5651e-01, -1.8353e-01,  6.9838e-01,  ...,\n",
      "            -2.3593e+00, -4.2479e-01,  4.3717e-01],\n",
      "           [ 4.6789e-01,  4.0053e-01, -9.2203e-02,  ...,\n",
      "             1.9795e-01,  4.5108e-01, -5.9367e-04],\n",
      "           ...,\n",
      "           [ 5.3743e-01, -3.8822e-01, -2.1267e+00,  ...,\n",
      "            -3.6070e-01,  1.8846e-01,  2.5597e-01],\n",
      "           [-7.7335e-01,  1.9743e-01,  1.0210e+00,  ...,\n",
      "            -7.1605e-01, -5.3083e-02,  1.8139e-01],\n",
      "           [ 1.5446e+00,  7.5812e-01,  6.2349e-01,  ...,\n",
      "             1.1822e+00,  5.3526e-01, -8.4451e-01]]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0576,  0.3725, -1.5197,  0.5702, -0.1751],\n",
      "        [-0.2004, -0.6745, -0.6581,  0.5599,  1.1707],\n",
      "        [-0.0292,  0.3049,  0.9087, -0.6320, -0.4456],\n",
      "        [ 0.2268,  2.5822,  0.2026,  0.4650, -0.8471]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 5 6]\n",
      " [0 8 9]]\n"
     ]
    }
   ],
   "source": [
    "c = np.array([[0,5,6],\n",
    "             [4,8,9]])\n",
    "c[c<5] = 0\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1286, -0.5315,  1.5995,  0.7629, -1.3348],\n",
      "        [ 0.8730,  0.3525,  0.3758, -0.9494,  1.1609],\n",
      "        [ 0.7572, -0.8587, -0.5924, -0.6697,  0.1279]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to comparison (<ipython-input-47-096d13b0e452>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-47-096d13b0e452>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    a[2,:]<0.1 = 0\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to comparison\n"
     ]
    }
   ],
   "source": [
    "a[2,:]<0.1 = 0\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.8346, -0.5374, -0.7030, -1.6648,  0.1096])\n"
     ]
    }
   ],
   "source": [
    "print(a[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,3,5,40,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 40, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,:,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
