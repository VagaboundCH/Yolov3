{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = 26+10+4   #Grossbuchstaben, Zahlen, {.:/-}\n",
    "anchors = [10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326]\n",
    "leaky_relu_value = 0.1\n",
    "number_anchors = np.size(anchors)/6\n",
    "features = int(number_anchors*(4+1+number_classes))\n",
    "dimension = 3\n",
    "ignore_thres = 0.7\n",
    "\n",
    "\n",
    "class Yolo_v3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Yolo_v3, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(dimension,32,3,stride=1,padding=1)\n",
    "        self.batch_1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(32,64,3,stride=2,padding=1)\n",
    "        self.batch_2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(64,32,1,stride=1,padding=0)\n",
    "        self.batch_3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv_4 = nn.Conv2d(32,64,3,stride=1,padding=1)\n",
    "        self.batch_4 = nn.BatchNorm2d(64)\n",
    "\n",
    "\n",
    "        \n",
    "        self.conv_6 = nn.Conv2d(64,128,3,stride=2,padding=1)\n",
    "        self.batch_6 = nn.BatchNorm2d(128)\n",
    "            \n",
    "        self.conv_7 = nn.Conv2d(128,64,1,stride=1,padding=0)\n",
    "        self.batch_7 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_8 = nn.Conv2d(64,128,3,stride=1,padding=1)\n",
    "        self.batch_8 = nn.BatchNorm2d(128)\n",
    " \n",
    "\n",
    "          \n",
    "        self.conv_10 = nn.Conv2d(128,64,1,stride=1,padding=0)\n",
    "        self.batch_10 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_11 = nn.Conv2d(64,128,3,stride=1,padding=1)\n",
    "        self.batch_11 = nn.BatchNorm2d(128)\n",
    "          \n",
    "\n",
    "             \n",
    "        self.conv_13 = nn.Conv2d(128,256,3,stride=2,padding=1)\n",
    "        self.batch_13 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_14 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_14 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_15 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_15 = nn.BatchNorm2d(256)        \n",
    "        \n",
    "\n",
    "\n",
    "        self.conv_17 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_17 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_18 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_18 = nn.BatchNorm2d(256)\n",
    "        \n",
    "       \n",
    "    \n",
    "        \n",
    "        self.conv_38 = nn.Conv2d(256,512,3,stride=2,padding=1)\n",
    "        self.batch_38 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_39 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_39 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_40 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_40 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_42 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_42 = nn.BatchNorm2d(256)        \n",
    "        \n",
    "        self.conv_43 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_43 = nn.BatchNorm2d(512)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.conv_63 = nn.Conv2d(512,1024,3,stride=2,padding=1)\n",
    "        self.batch_63 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv_64 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_64 = nn.BatchNorm2d(512)        \n",
    "        \n",
    "        self.conv_65 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_65 = nn.BatchNorm2d(1024)  \n",
    "        \n",
    "\n",
    "        \n",
    "        self.conv_67 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_67 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_68 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_68 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_76 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_76 = nn.BatchNorm2d(512)        \n",
    "        \n",
    "        self.conv_77 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_77 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv_82 = nn.Conv2d(1024,features,1,stride=1,padding=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_85 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_85 = nn.BatchNorm2d(256)       \n",
    "\n",
    "        self.convT_86 = nn.ConvTranspose2d(256,256,3,stride=2,padding=1,output_padding=1)\n",
    "        self.batch_86 = nn.BatchNorm2d(256) \n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv_88 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_88 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_89 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_89 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_94 = nn.Conv2d(512,features,1,stride=1,padding=0)\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        self.conv_97 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_97 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.convT_98 = nn.ConvTranspose2d(128,128,3,stride=2,padding=1,output_padding=1)\n",
    "        self.batch_98 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_100 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_100 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_101 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_101 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_106 = nn.Conv2d(256,features,1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        layer_1 = F.leaky_relu(self.batch_1(self.conv_1(inputs)),leaky_relu_value,True)\n",
    "        layer_2 = F.leaky_relu(self.batch_2(self.conv_2(layer_1)),leaky_relu_value,True)\n",
    "        layer_3 = F.leaky_relu(self.batch_3(self.conv_3(layer_2)),leaky_relu_value,True)\n",
    "        layer_4 = F.leaky_relu(self.batch_4(self.conv_4(layer_3)),leaky_relu_value,True)\n",
    "        layer_5 = layer_2 + layer_4\n",
    "        layer_6 = F.leaky_relu(self.batch_6(self.conv_6(layer_5)),leaky_relu_value,True)\n",
    "        layer_7 = F.leaky_relu(self.batch_7(self.conv_7(layer_6)),leaky_relu_value,True)\n",
    "        layer_8 = F.leaky_relu(self.batch_8(self.conv_8(layer_7)),leaky_relu_value,True)\n",
    "        layer_9 = layer_6 + layer_8\n",
    "        layer_10 = F.leaky_relu(self.batch_10(self.conv_10(layer_9)),leaky_relu_value,True)\n",
    "        layer_11 = F.leaky_relu(self.batch_11(self.conv_11(layer_10)),leaky_relu_value,True)\n",
    "        layer_12 = layer_9 + layer_11\n",
    "        layer_13 = F.leaky_relu(self.batch_13(self.conv_13(layer_12)),leaky_relu_value,True)\n",
    "        layer_14 = F.leaky_relu(self.batch_14(self.conv_14(layer_13)),leaky_relu_value,True)\n",
    "        layer_15 = F.leaky_relu(self.batch_15(self.conv_15(layer_14)),leaky_relu_value,True)\n",
    "        layer_16 = layer_13 + layer_15\n",
    "        layer_17 = F.leaky_relu(self.batch_17(self.conv_17(layer_16)),leaky_relu_value,True)\n",
    "        layer_18 = F.leaky_relu(self.batch_18(self.conv_18(layer_17)),leaky_relu_value,True)\n",
    "        layer_19 = layer_16 + layer_18      \n",
    "        layer_20 = F.leaky_relu(self.batch_17(self.conv_17(layer_19)),leaky_relu_value,True)\n",
    "        layer_21 = F.leaky_relu(self.batch_18(self.conv_18(layer_20)),leaky_relu_value,True)\n",
    "        layer_22 = layer_19 + layer_21\n",
    "        layer_23 = F.leaky_relu(self.batch_17(self.conv_17(layer_22)),leaky_relu_value,True)\n",
    "        layer_24 = F.leaky_relu(self.batch_18(self.conv_18(layer_23)),leaky_relu_value,True)\n",
    "        layer_25 = layer_22 + layer_24\n",
    "        layer_26 = F.leaky_relu(self.batch_17(self.conv_17(layer_25)),leaky_relu_value,True)\n",
    "        layer_27 = F.leaky_relu(self.batch_18(self.conv_18(layer_26)),leaky_relu_value,True)\n",
    "        layer_28 = layer_25 + layer_27\n",
    "        layer_29 = F.leaky_relu(self.batch_17(self.conv_17(layer_28)),leaky_relu_value,True)\n",
    "        layer_30 = F.leaky_relu(self.batch_18(self.conv_18(layer_29)),leaky_relu_value,True)\n",
    "        layer_31 = layer_28 + layer_30\n",
    "        layer_32 = F.leaky_relu(self.batch_17(self.conv_17(layer_31)),leaky_relu_value,True)\n",
    "        layer_33 = F.leaky_relu(self.batch_18(self.conv_18(layer_32)),leaky_relu_value,True)\n",
    "        layer_34 = layer_31 + layer_33\n",
    "        layer_35 = F.leaky_relu(self.batch_17(self.conv_17(layer_34)),leaky_relu_value,True)\n",
    "        layer_36 = F.leaky_relu(self.batch_18(self.conv_18(layer_35)),leaky_relu_value,True)\n",
    "        layer_37 = layer_34 + layer_36\n",
    "        layer_38 = F.leaky_relu(self.batch_38(self.conv_38(layer_37)),leaky_relu_value,True)\n",
    "        layer_39 = F.leaky_relu(self.batch_39(self.conv_39(layer_38)),leaky_relu_value,True)\n",
    "        layer_40 = F.leaky_relu(self.batch_40(self.conv_40(layer_39)),leaky_relu_value,True)\n",
    "        layer_41 = layer_38 + layer_40\n",
    "        layer_42 = F.leaky_relu(self.batch_42(self.conv_42(layer_41)),leaky_relu_value,True)\n",
    "        layer_43 = F.leaky_relu(self.batch_43(self.conv_43(layer_42)),leaky_relu_value,True)\n",
    "        layer_44 = layer_41 + layer_43\n",
    "        layer_45 = F.leaky_relu(self.batch_42(self.conv_42(layer_44)),leaky_relu_value,True)\n",
    "        layer_46 = F.leaky_relu(self.batch_43(self.conv_43(layer_45)),leaky_relu_value,True)\n",
    "        layer_47 = layer_44 + layer_46\n",
    "        layer_48 = F.leaky_relu(self.batch_42(self.conv_42(layer_47)),leaky_relu_value,True)\n",
    "        layer_49 = F.leaky_relu(self.batch_43(self.conv_43(layer_48)),leaky_relu_value,True)\n",
    "        layer_50 = layer_47 + layer_49\n",
    "        layer_51 = F.leaky_relu(self.batch_42(self.conv_42(layer_50)),leaky_relu_value,True)\n",
    "        layer_52 = F.leaky_relu(self.batch_43(self.conv_43(layer_51)),leaky_relu_value,True)\n",
    "        layer_53 = layer_50 + layer_52\n",
    "        layer_54 = F.leaky_relu(self.batch_42(self.conv_42(layer_53)),leaky_relu_value,True)\n",
    "        layer_55 = F.leaky_relu(self.batch_43(self.conv_43(layer_54)),leaky_relu_value,True)\n",
    "        layer_56 = layer_53 +layer_55\n",
    "        layer_57 = F.leaky_relu(self.batch_42(self.conv_42(layer_56)),leaky_relu_value,True)\n",
    "        layer_58 = F.leaky_relu(self.batch_43(self.conv_43(layer_57)),leaky_relu_value,True)\n",
    "        layer_59 = layer_56 + layer_58\n",
    "        layer_60 = F.leaky_relu(self.batch_42(self.conv_42(layer_59)),leaky_relu_value,True)\n",
    "        layer_61 = F.leaky_relu(self.batch_43(self.conv_43(layer_60)),leaky_relu_value,True)\n",
    "        layer_62 = layer_59 + layer_61\n",
    "        layer_63 = F.leaky_relu(self.batch_63(self.conv_63(layer_62)),leaky_relu_value,True)\n",
    "        layer_64 = F.leaky_relu(self.batch_64(self.conv_64(layer_63)),leaky_relu_value,True)\n",
    "        layer_65 = F.leaky_relu(self.batch_65(self.conv_65(layer_64)),leaky_relu_value,True)\n",
    "        layer_66 = layer_63 + layer_65\n",
    "        layer_67 = F.leaky_relu(self.batch_67(self.conv_67(layer_66)),leaky_relu_value,True)\n",
    "        layer_68 = F.leaky_relu(self.batch_68(self.conv_68(layer_67)),leaky_relu_value,True)\n",
    "        layer_69 = layer_66 + layer_68\n",
    "        layer_70 = F.leaky_relu(self.batch_67(self.conv_67(layer_69)),leaky_relu_value,True)\n",
    "        layer_71 = F.leaky_relu(self.batch_68(self.conv_68(layer_70)),leaky_relu_value,True)\n",
    "        layer_72 = layer_69 + layer_71\n",
    "        layer_73 = F.leaky_relu(self.batch_67(self.conv_67(layer_72)),leaky_relu_value,True)\n",
    "        layer_74 = F.leaky_relu(self.batch_68(self.conv_68(layer_73)),leaky_relu_value,True)\n",
    "        layer_75 = layer_72 + layer_74\n",
    "        layer_76 = F.leaky_relu(self.batch_76(self.conv_76(layer_75)),leaky_relu_value,True)\n",
    "        layer_77 = F.leaky_relu(self.batch_77(self.conv_77(layer_76)),leaky_relu_value,True)\n",
    "        layer_78 = F.leaky_relu(self.batch_76(self.conv_76(layer_77)),leaky_relu_value,True)\n",
    "        layer_79 = F.leaky_relu(self.batch_77(self.conv_77(layer_78)),leaky_relu_value,True)\n",
    "        layer_80 = F.leaky_relu(self.batch_76(self.conv_76(layer_79)),leaky_relu_value,True)\n",
    "        layer_81 = F.leaky_relu(self.batch_77(self.conv_77(layer_80)),leaky_relu_value,True)\n",
    "        layer_82 = self.conv_82(layer_81)\n",
    "        layer_83 = layer_82\n",
    "        layer_84 = layer_80   # 16x16\n",
    "        layer_85 = F.leaky_relu(self.batch_85(self.conv_85(layer_84)),leaky_relu_value,True)\n",
    "        layer_86 = F.leaky_relu(self.batch_86(self.convT_86(layer_85)),leaky_relu_value,True)\n",
    "        layer_87 = torch.cat((layer_60,layer_86),1)\n",
    "        layer_88 = F.leaky_relu(self.batch_88(self.conv_88(layer_87)),leaky_relu_value,True)\n",
    "        layer_89 = F.leaky_relu(self.batch_89(self.conv_89(layer_88)),leaky_relu_value,True)\n",
    "        layer_90 = F.leaky_relu(self.batch_88(self.conv_88(layer_89)),leaky_relu_value,True)\n",
    "        layer_91 = F.leaky_relu(self.batch_89(self.conv_89(layer_90)),leaky_relu_value,True)\n",
    "        layer_92 = F.leaky_relu(self.batch_88(self.conv_88(layer_91)),leaky_relu_value,True)\n",
    "        layer_93 = F.leaky_relu(self.batch_89(self.conv_89(layer_92)),leaky_relu_value,True)\n",
    "        layer_94 = self.conv_94(layer_93)\n",
    "        layer_95 = layer_94\n",
    "        layer_96 = layer_92   # 32x32\n",
    "        layer_97 = F.leaky_relu(self.batch_97(self.conv_97(layer_96)),leaky_relu_value,True)\n",
    "        layer_98 = F.leaky_relu(self.batch_98(self.convT_98(layer_97)),leaky_relu_value,True)\n",
    "        layer_99 = torch.cat((layer_35,layer_98),1)\n",
    "        layer_100 = F.leaky_relu(self.batch_100(self.conv_100(layer_99)),leaky_relu_value,True)\n",
    "        layer_101 = F.leaky_relu(self.batch_101(self.conv_101(layer_100)),leaky_relu_value,True)\n",
    "        layer_102 = F.leaky_relu(self.batch_100(self.conv_100(layer_101)),leaky_relu_value,True)\n",
    "        layer_103 = F.leaky_relu(self.batch_101(self.conv_101(layer_102)),leaky_relu_value,True)\n",
    "        layer_104 = F.leaky_relu(self.batch_100(self.conv_100(layer_103)),leaky_relu_value,True)\n",
    "        layer_105 = F.leaky_relu(self.batch_101(self.conv_101(layer_104)),leaky_relu_value,True)\n",
    "        layer_106 = self.conv_106(layer_105)\n",
    "        layer_107 = layer_106   # 64x64\n",
    "        return layer_83, layer_95, layer_106   # ...*3*(5+26+10+4) = 135\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yolo_v3(\n",
      "  (conv_1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_7): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_10): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_13): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_14): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_15): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_17): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_18): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_38): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_39): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_39): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_40): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_42): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_42): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_43): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_63): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_63): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_64): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_65): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_65): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_67): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_68): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_68): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_76): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_76): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_77): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_77): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_82): Conv2d(1024, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_85): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_85): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (convT_86): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (batch_86): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_88): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_88): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_89): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_89): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_94): Conv2d(512, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_97): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_97): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (convT_98): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (batch_98): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_100): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_100): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_101): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_101): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_106): Conv2d(256, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Yolo_v3()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 135, 16, 16]) torch.Size([1, 135, 32, 32]) torch.Size([1, 135, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 512, 512)\n",
    "output_layer_1, output_layer_2, output_layer_3 = net(x)\n",
    "print(output_layer_1.size(),output_layer_2.size(),output_layer_3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer_dim(output_layer):\n",
    "    batch_number, outputs, y, x = output_layer.shape\n",
    "    return output_layer_1.view(batch_number, number_anchors, 5, outputs/5/number_anchors, y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 9, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(output_layer_dim(output_layer_1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: yolo_filter_boxes\n",
    "\n",
    "def yolo_filter_boxes(output_layer, ignore_thresh  = 0.7):\n",
    "    \"\"\"Filters YOLO boxes by thresholding on object and class confidence.\n",
    "    \n",
    "    Arguments:\n",
    "    box_confidence -- tensor of shape (19, 19, 5, 1)   (1,anchor_number,1,y,x)\n",
    "    boxes -- tensor of shape (19, 19, 5, 4)   (1,anchor_number,4,y,x)\n",
    "    box_class_probs -- tensor of shape (19, 19, 5, 80)   (1,anchor_number,classes,y,x)\n",
    "    threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None,), containing the class probability score for selected boxes\n",
    "    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes\n",
    "    classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes\n",
    "    \n",
    "    Note: \"None\" is here because you don't know the exact number of selected boxes, as it depends on the threshold. \n",
    "    For example, the actual output size of scores would be (10,) if there are 10 boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    box_confidence = output_layer\n",
    "    box_confidence[:,:,0<ingore_tresh,:,:] = 0\n",
    "    \n",
    "    # Step 1: Compute box scores\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    box_scores = box_confidence[:,:,0,:,:,:] * box_class_probs[:,:,:,:,:,:] # 19x19x80   1,3,1,x,y * 1,3,\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 2: Find the box_classes thanks to the max box_scores, keep track of the corresponding score\n",
    "    ### START CODE HERE ### (≈ 2 lines)\n",
    "    box_classes = K.argmax(box_scores, axis = -1)  # 19x19x5x1  (1 class index)\n",
    "    box_class_scores = K.max(box_scores, axis = -1)  # 19x19x5x1 (1 class score)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 3: Create a filtering mask based on \"box_class_scores\" by using \"threshold\". The mask should have the\n",
    "    # same dimension as box_class_scores, and be True for the boxes you want to keep (with probability >= threshold)\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    filtering_mask = box_class_scores >= threshold\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 4: Apply the mask to scores, boxes and classes\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24])\n",
      "tensor([[-0.5010,  1.3612,  0.2611,  1.1507,  0.5662,  0.8486,  1.4634,\n",
      "         -0.7691,  0.6056,  1.1778,  1.2709,  0.5941, -1.3133, -3.1274,\n",
      "         -0.1573, -3.1905, -1.4463, -0.5437,  0.1982, -1.0954,  0.4507,\n",
      "         -1.0748,  0.3555,  1.3461]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,24)\n",
    "print(a.size())\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 8])\n",
      "tensor([[[-0.5010,  1.3612,  0.2611,  1.1507,  0.5662,  0.8486,  1.4634,\n",
      "          -0.7691],\n",
      "         [ 0.6056,  1.1778,  1.2709,  0.5941, -1.3133, -3.1274, -0.1573,\n",
      "          -3.1905],\n",
      "         [-1.4463, -0.5437,  0.1982, -1.0954,  0.4507, -1.0748,  0.3555,\n",
      "           1.3461]]])\n"
     ]
    }
   ],
   "source": [
    "b = a.view(1,3,8)\n",
    "print(b.size())\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([1, 1, 12, 12])\n",
      "b:  torch.Size([1, 1, 6, 6])\n",
      "c:  torch.Size([1, 1, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,1,12,12)\n",
    "conv = nn.Conv2d(1,1,3, stride=2,padding=1)\n",
    "convT = nn.ConvTranspose2d(1,1,3,stride=2,padding=0)\n",
    "\n",
    "b = conv(a)\n",
    "c = convT(b)\n",
    "\n",
    "print(\"a: \", a.size())\n",
    "print(\"b: \", b.size())\n",
    "print(\"c: \", c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d:  torch.Size([1, 1, 6, 6])\n",
      "ConvTranspose2d:  torch.Size([1, 1, 24, 24])\n",
      "Conv2d und ConvTranspose2d:  torch.Size([1, 1, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1, 1, 12, 12)   # Batch, Anzahl channels, X,Y \n",
    "downsample = nn.Conv2d(1, 1, 3, stride=2, padding=1)\n",
    "upsample = nn.ConvTranspose2d(1, 1, 3, stride=2, padding=1,output_padding=1)\n",
    "h = downsample(inputs)\n",
    "print('Conv2d: ', h.size())        # (1, 1, 6, 6)\n",
    "output = upsample(inputs)\n",
    "print('ConvTranspose2d: ', output.size())    # (1, 1, 12, 12)\n",
    "g = upsample(h)\n",
    "print('Conv2d und ConvTranspose2d: ', g.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 16, 16])\n",
      "torch.Size([1, 3, 40, 16, 16])\n",
      "torch.Size([1, 3, 40, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,45,16,16)\n",
    "b = torch.randn(1,3,45,16,16)\n",
    "a_1 = a[:,:,0:1,:,:]\n",
    "b_1 = b[:,:,5:45,:,:]\n",
    "print(a_1.size())\n",
    "print(b_1.size())\n",
    "c = a_1 * b_1\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0.9762,  0.5120,  0.5376],\n",
      "           [ 0.9239,  0.3237, -0.0567],\n",
      "           [-0.3384, -1.1137,  0.1261]],\n",
      "\n",
      "          [[-1.1187,  0.5280,  1.3983],\n",
      "           [ 0.7243, -1.1578,  0.2710],\n",
      "           [-1.8831,  0.0172, -0.2069]],\n",
      "\n",
      "          [[ 1.7011,  0.6538, -1.0840],\n",
      "           [-0.4891, -1.7829,  2.2199],\n",
      "           [ 0.5811, -1.0234,  0.2109]],\n",
      "\n",
      "          [[ 0.9116, -0.4261,  0.3543],\n",
      "           [-1.0030,  1.6959,  0.0917],\n",
      "           [-0.8609,  2.2440, -2.1287]],\n",
      "\n",
      "          [[-1.2606, -1.8732, -0.3756],\n",
      "           [-0.2979, -1.2271,  0.6245],\n",
      "           [-0.3172, -0.6638, -0.7635]],\n",
      "\n",
      "          [[-0.0395, -0.1179,  1.5163],\n",
      "           [-0.4205, -0.9245,  0.1859],\n",
      "           [ 0.7814, -1.3002, -0.3895]],\n",
      "\n",
      "          [[ 0.1565,  0.5244, -0.9540],\n",
      "           [ 0.2609, -0.3402,  0.6032],\n",
      "           [-2.2248,  0.3652,  0.8307]],\n",
      "\n",
      "          [[ 1.1097,  0.2464,  0.1761],\n",
      "           [ 0.5225,  0.6369,  0.7437],\n",
      "           [ 0.8980, -0.0873,  0.0365]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1972, -0.7262, -0.1164],\n",
      "           [-1.0782,  1.0176, -2.3790],\n",
      "           [ 0.6703, -0.6383, -0.9119]],\n",
      "\n",
      "          [[-1.2498, -0.7078, -0.1343],\n",
      "           [-0.2913,  0.3142,  0.8505],\n",
      "           [ 0.2286,  1.1114,  0.9764]],\n",
      "\n",
      "          [[ 0.2962,  0.4007, -0.4494],\n",
      "           [ 0.2213,  1.4968,  1.5701],\n",
      "           [-0.0678,  1.5513, -0.3318]],\n",
      "\n",
      "          [[-3.3786, -0.1698, -0.2938],\n",
      "           [ 0.1829,  1.0500, -0.9971],\n",
      "           [-0.6053,  0.3543,  1.5194]],\n",
      "\n",
      "          [[ 0.2721,  0.2444, -0.1564],\n",
      "           [-0.0945,  1.5853, -0.2536],\n",
      "           [-0.0478, -0.0837, -0.5623]],\n",
      "\n",
      "          [[-1.0598,  0.6326,  0.8234],\n",
      "           [ 1.5882, -0.8623, -1.0190],\n",
      "           [ 0.0870,  2.2905,  1.1939]],\n",
      "\n",
      "          [[-0.8446, -0.4732,  0.2370],\n",
      "           [ 1.0442,  0.4875, -0.4945],\n",
      "           [-0.3000, -0.4764, -1.8058]],\n",
      "\n",
      "          [[-0.3211, -1.0094,  0.4392],\n",
      "           [-0.3466,  0.8685,  1.8995],\n",
      "           [ 1.2844,  1.8860, -0.2663]]],\n",
      "\n",
      "\n",
      "         [[[ 1.5317,  0.8601, -1.5487],\n",
      "           [-0.3136, -0.6319, -1.9570],\n",
      "           [ 0.0678,  1.0627,  0.2347]],\n",
      "\n",
      "          [[-1.3830,  0.7136, -0.0747],\n",
      "           [-2.3041, -1.2027,  1.7248],\n",
      "           [-1.8373, -3.0640, -1.5557]],\n",
      "\n",
      "          [[-0.9142,  2.2555, -0.1863],\n",
      "           [ 1.0040,  0.2837,  0.1703],\n",
      "           [-1.6489, -0.4044,  0.4203]],\n",
      "\n",
      "          [[ 1.1734, -0.0090, -0.7181],\n",
      "           [ 0.3069, -0.1980,  1.8636],\n",
      "           [-0.6308,  0.1178,  0.6630]],\n",
      "\n",
      "          [[-0.0703,  0.1554, -0.2176],\n",
      "           [-0.5174,  2.4005, -1.0682],\n",
      "           [ 1.2642, -0.0479, -0.1101]],\n",
      "\n",
      "          [[-1.3746,  0.9454,  0.5834],\n",
      "           [-0.0773,  0.2368,  0.2908],\n",
      "           [-1.1072,  0.2482, -1.2915]],\n",
      "\n",
      "          [[ 1.2640,  0.6635,  1.3519],\n",
      "           [-1.2780, -0.7865,  1.1968],\n",
      "           [-1.2868,  0.3840, -0.5895]],\n",
      "\n",
      "          [[-0.2350, -0.8253,  1.2935],\n",
      "           [ 0.3075, -0.5612,  0.1959],\n",
      "           [ 0.5764,  1.5669,  0.5753]]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,8,3,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.9762,  0.5120,  0.5376],\n",
      "          [ 0.9239,  0.3237, -0.0567],\n",
      "          [-0.3384, -1.1137,  0.1261]],\n",
      "\n",
      "         [[ 0.1972, -0.7262, -0.1164],\n",
      "          [-1.0782,  1.0176, -2.3790],\n",
      "          [ 0.6703, -0.6383, -0.9119]],\n",
      "\n",
      "         [[ 1.5317,  0.8601, -1.5487],\n",
      "          [-0.3136, -0.6319, -1.9570],\n",
      "          [ 0.0678,  1.0627,  0.2347]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a[:,:,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_output[:,:,0,:,:] => pc\n",
    "# layer_output[:,:,1,:,:] => bx\n",
    "# layer_output[:,:,2,:,:] => by\n",
    "# layer_output[:,:,3,:,:] => tx\n",
    "# layer_output[:,:,4,:,:] => ty\n",
    "# layer_output[:,:,5,:,:] => c1\n",
    "# layer_output[:,:,n,:,:] => cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-0.8149,  1.3050,  0.8988],\n",
      "           [-0.0289,  0.2133, -0.4548],\n",
      "           [ 0.3085, -0.9921,  0.4419]],\n",
      "\n",
      "          [[-0.4809,  0.8808,  0.8594],\n",
      "           [ 0.9602, -0.8180,  0.0453],\n",
      "           [ 0.4767, -1.9962, -0.0317]],\n",
      "\n",
      "          [[ 1.1382, -1.3587,  0.9941],\n",
      "           [ 0.8660,  2.5502, -0.3065],\n",
      "           [-0.4971, -0.0391, -1.3088]]],\n",
      "\n",
      "\n",
      "         [[[-0.9403,  0.3480, -0.2898],\n",
      "           [ 0.0680, -0.1100, -0.7302],\n",
      "           [-1.6528, -0.1860,  0.9175]],\n",
      "\n",
      "          [[ 1.4651, -0.6903,  0.6979],\n",
      "           [-0.2908, -0.8185,  0.6753],\n",
      "           [ 0.0986, -1.0006,  0.0808]],\n",
      "\n",
      "          [[ 0.6930, -1.0513,  0.2692],\n",
      "           [-0.7237,  0.1671, -0.0008],\n",
      "           [-0.1817,  1.1708,  0.5300]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2645,  1.1454,  1.6934],\n",
      "           [-0.0582, -0.5861,  1.3110],\n",
      "           [-0.3479, -0.9814,  0.1526]],\n",
      "\n",
      "          [[-1.4726, -0.8433,  0.3236],\n",
      "           [ 0.1738,  0.4888,  0.1624],\n",
      "           [-0.7360, -0.6623, -0.3939]],\n",
      "\n",
      "          [[ 1.3607,  0.6224,  0.5630],\n",
      "           [ 0.5064, -0.7830,  0.2251],\n",
      "           [-0.2032, -0.7944, -1.3116]]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a[:,:,5:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_index(tmp, ignore_thres = 0.7):\n",
    "    tmp1 = torch.cat((tmp[:,0,:,:,:], tmp[:,1,:,:,:], tmp[:,2,:,:,:]),1)\n",
    "    d_max, d_max_index = torch.max(tmp1,1)\n",
    "    batch_size, tmp_number_classes, y, x = tmp1.shape\n",
    "    tmp_tensor = torch.zeros(batch_size, tmp_number_classes, y, x)\n",
    "    \n",
    "    for i in range(y):\n",
    "        for j in range(x):\n",
    "            position = d_max_index[0,i,j]\n",
    "            tmp_tensor[0,position,i,j] = 1\n",
    "            if tmp1[0,position,i,j] < ignore_thres:\n",
    "                tmp_tensor[0,position,i,j] = 0\n",
    "    return tmp_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_surpression(layer_output, ignore_threshold = 0.7):\n",
    "    box_scores = torch.mul(layer_output[:,:,5:,:,:], layer_output[:,:,0,:,:]) # confidence * class score\n",
    "    filter_mask = max_confidence(box_scores, ignore_threshold = 0.7)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 1.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  1.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  1.]],\n",
      "\n",
      "         [[ 1.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  1.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  1.],\n",
      "          [ 0.,  0.,  1.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]]]])\n"
     ]
    }
   ],
   "source": [
    "z = max_index(c,0.7)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,8,3,3)\n",
    "b = non_max_surpression(a,0.7)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n",
      "tensor([[[[[ 0.1567,  0.2116,  0.4470],\n",
      "           [ 0.0388, -0.3436, -0.1389],\n",
      "           [-0.2684,  0.5723,  0.8842]],\n",
      "\n",
      "          [[-0.2455, -1.3099,  1.3137],\n",
      "           [ 0.2063, -0.9575,  0.0641],\n",
      "           [-0.0270, -0.1416,  0.0129]],\n",
      "\n",
      "          [[ 0.3346,  1.7525,  1.0157],\n",
      "           [-0.0269, -0.8652,  0.1784],\n",
      "           [-0.9548,  0.0169, -1.0450]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1808,  0.0564, -0.1441],\n",
      "           [-0.0912,  0.1771, -0.2231],\n",
      "           [ 1.4383,  0.1073,  1.8358]],\n",
      "\n",
      "          [[ 0.7480,  1.0265,  1.0668],\n",
      "           [-0.0625, -0.9580,  0.9552],\n",
      "           [-0.0056, -0.0710, -0.0329]],\n",
      "\n",
      "          [[ 0.2037,  1.3560,  0.2751],\n",
      "           [ 0.0224, -0.0567,  0.0004],\n",
      "           [-0.3490, -0.5054,  0.4232]]],\n",
      "\n",
      "\n",
      "         [[[-0.0508,  0.1858,  0.8422],\n",
      "           [ 0.0781,  0.9442,  0.4005],\n",
      "           [ 0.3027,  0.5661,  0.3054]],\n",
      "\n",
      "          [[-0.7518,  1.2542,  0.4947],\n",
      "           [ 0.0373,  0.5722,  0.2297],\n",
      "           [ 0.0416, -0.0470,  0.1605]],\n",
      "\n",
      "          [[ 0.4000, -0.8028,  0.5752],\n",
      "           [-0.0157,  0.2656, -0.1310],\n",
      "           [-0.3902,  0.3429, -1.0473]]]]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.mul(a[:,:,5:,:,:], a[:,:,0,:,:])\n",
    "print(b.size())\n",
    "# b[b<0.1] = 0\n",
    "# b[b>=0.1] = 1\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   box_classes = K.argmax(box_scores, axis = -1)  # 19x19x5x1  (1 class index)\n",
    "#  box_class_scores = K.max(box_scores, axis = -1)  # 19x19x5x1 (1 class score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0.1453,  0.3222, -0.8677],\n",
      "           [ 0.3942, -0.8767,  0.0186],\n",
      "           [-0.0429, -0.5691, -0.1548]],\n",
      "\n",
      "          [[ 1.4984, -0.6764, -0.3858],\n",
      "           [-0.1393, -0.5445, -0.3784],\n",
      "           [-0.0058,  0.9321,  1.5658]],\n",
      "\n",
      "          [[-0.0042, -0.9975,  0.1681],\n",
      "           [-0.7926,  1.1236,  0.0412],\n",
      "           [ 0.2972, -0.1403, -0.3645]],\n",
      "\n",
      "          [[-0.3765, -0.8055, -0.6821],\n",
      "           [-0.3558,  2.1598,  2.1103],\n",
      "           [ 0.1300, -0.3741,  0.0757]],\n",
      "\n",
      "          [[-2.5740, -0.5574, -0.7684],\n",
      "           [ 1.2945, -0.0641, -0.8182],\n",
      "           [-2.1312, -0.6864, -0.2527]],\n",
      "\n",
      "          [[-0.8003,  0.7683, -1.0649],\n",
      "           [ 1.8570, -0.8143, -0.5750],\n",
      "           [-1.3593, -0.9354, -0.1103]],\n",
      "\n",
      "          [[ 0.0672,  0.3824,  0.7212],\n",
      "           [ 2.9575, -1.2002, -1.2147],\n",
      "           [ 1.3152, -0.3910, -1.7388]],\n",
      "\n",
      "          [[-1.1646,  0.1989,  0.9756],\n",
      "           [-1.2275, -0.3666, -0.0395],\n",
      "           [ 0.1581, -1.8811, -0.5720]]],\n",
      "\n",
      "\n",
      "         [[[-0.6556,  0.6233,  1.3132],\n",
      "           [ 0.8257, -1.1156,  0.1855],\n",
      "           [-0.2171,  1.7124, -1.4058]],\n",
      "\n",
      "          [[-1.0323, -1.0515,  0.7021],\n",
      "           [-1.4100, -0.3313,  1.3009],\n",
      "           [ 1.1451, -0.8084, -0.0901]],\n",
      "\n",
      "          [[-0.4183, -1.9805,  1.1174],\n",
      "           [ 1.3895, -0.2220,  0.0268],\n",
      "           [ 0.8606, -0.3749,  1.3940]],\n",
      "\n",
      "          [[-0.3879, -0.9756,  0.1065],\n",
      "           [ 0.8104,  1.0158,  0.8491],\n",
      "           [-2.4179,  1.1393,  0.2565]],\n",
      "\n",
      "          [[ 0.0105, -1.9618, -0.4124],\n",
      "           [ 2.3191,  0.2469, -1.8353],\n",
      "           [-0.4983, -0.7022, -0.1076]],\n",
      "\n",
      "          [[-1.8747, -1.6715, -1.3859],\n",
      "           [-0.5295, -0.5642, -0.6924],\n",
      "           [-0.5394,  0.5514,  1.5575]],\n",
      "\n",
      "          [[ 2.5219,  0.6018,  0.9833],\n",
      "           [ 0.0880,  0.2821,  0.7378],\n",
      "           [-0.7471, -1.3530, -1.9507]],\n",
      "\n",
      "          [[ 0.7796, -0.1643, -0.4532],\n",
      "           [-1.5558, -0.2120,  0.2170],\n",
      "           [-1.5331, -0.8501,  1.0216]]],\n",
      "\n",
      "\n",
      "         [[[ 0.6638, -0.6788,  0.4855],\n",
      "           [ 0.7685,  2.4586,  0.8653],\n",
      "           [ 1.3930, -0.8926,  0.7569]],\n",
      "\n",
      "          [[ 0.0404,  0.6929, -0.9280],\n",
      "           [ 1.5205,  1.0830,  0.1294],\n",
      "           [-0.6133,  0.8962,  0.8376]],\n",
      "\n",
      "          [[ 0.4329,  0.9391, -0.1937],\n",
      "           [-0.2987,  0.1866,  0.7659],\n",
      "           [ 0.0021,  0.9695,  0.3558]],\n",
      "\n",
      "          [[-0.4868,  0.3647, -0.0406],\n",
      "           [-1.7198, -3.5157,  1.2544],\n",
      "           [ 1.7959,  0.4936, -0.0069]],\n",
      "\n",
      "          [[ 0.2877,  1.0932,  1.6533],\n",
      "           [-0.4925, -1.0968,  0.2994],\n",
      "           [ 2.5744,  0.3388, -1.0890]],\n",
      "\n",
      "          [[-0.1025,  0.3199,  0.5447],\n",
      "           [-0.9048,  0.0820,  0.1154],\n",
      "           [-0.2631,  0.2083, -2.6952]],\n",
      "\n",
      "          [[-0.3947, -1.2871,  1.6479],\n",
      "           [-0.1356, -1.6607,  1.6340],\n",
      "           [ 1.0280,  1.4279, -0.7323]],\n",
      "\n",
      "          [[-1.3484,  1.7652, -0.8194],\n",
      "           [-0.1863, -0.3945,  0.2421],\n",
      "           [-0.3758, -0.3954,  0.3801]]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,8,3,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-0.8149,  1.3050,  0.8988],\n",
      "           [-0.0289,  0.2133, -0.4548],\n",
      "           [ 0.3085, -0.9921,  0.4419]],\n",
      "\n",
      "          [[-0.4809,  0.8808,  0.8594],\n",
      "           [ 0.9602, -0.8180,  0.0453],\n",
      "           [ 0.4767, -1.9962, -0.0317]],\n",
      "\n",
      "          [[ 1.1382, -1.3587,  0.9941],\n",
      "           [ 0.8660,  2.5502, -0.3065],\n",
      "           [-0.4971, -0.0391, -1.3088]]],\n",
      "\n",
      "\n",
      "         [[[-0.9403,  0.3480, -0.2898],\n",
      "           [ 0.0680, -0.1100, -0.7302],\n",
      "           [-1.6528, -0.1860,  0.9175]],\n",
      "\n",
      "          [[ 1.4651, -0.6903,  0.6979],\n",
      "           [-0.2908, -0.8185,  0.6753],\n",
      "           [ 0.0986, -1.0006,  0.0808]],\n",
      "\n",
      "          [[ 0.6930, -1.0513,  0.2692],\n",
      "           [-0.7237,  0.1671, -0.0008],\n",
      "           [-0.1817,  1.1708,  0.5300]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2645,  1.1454,  1.6934],\n",
      "           [-0.0582, -0.5861,  1.3110],\n",
      "           [-0.3479, -0.9814,  0.1526]],\n",
      "\n",
      "          [[-1.4726, -0.8433,  0.3236],\n",
      "           [ 0.1738,  0.4888,  0.1624],\n",
      "           [-0.7360, -0.6623, -0.3939]],\n",
      "\n",
      "          [[ 1.3607,  0.6224,  0.5630],\n",
      "           [ 0.5064, -0.7830,  0.2251],\n",
      "           [-0.2032, -0.7944, -1.3116]]]]])\n"
     ]
    }
   ],
   "source": [
    "c = a[:,:,5:,:,:]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n",
      "torch.Size([1, 9, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "c1 = torch.cat((c[:,0,:,:,:], c[:,1,:,:,:], c[:,2,:,:,:]),1)\n",
    "print(c.size())\n",
    "print(c1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.8149,  1.3050,  0.8988],\n",
      "          [-0.0289,  0.2133, -0.4548],\n",
      "          [ 0.3085, -0.9921,  0.4419]],\n",
      "\n",
      "         [[-0.4809,  0.8808,  0.8594],\n",
      "          [ 0.9602, -0.8180,  0.0453],\n",
      "          [ 0.4767, -1.9962, -0.0317]],\n",
      "\n",
      "         [[ 1.1382, -1.3587,  0.9941],\n",
      "          [ 0.8660,  2.5502, -0.3065],\n",
      "          [-0.4971, -0.0391, -1.3088]],\n",
      "\n",
      "         [[-0.9403,  0.3480, -0.2898],\n",
      "          [ 0.0680, -0.1100, -0.7302],\n",
      "          [-1.6528, -0.1860,  0.9175]],\n",
      "\n",
      "         [[ 1.4651, -0.6903,  0.6979],\n",
      "          [-0.2908, -0.8185,  0.6753],\n",
      "          [ 0.0986, -1.0006,  0.0808]],\n",
      "\n",
      "         [[ 0.6930, -1.0513,  0.2692],\n",
      "          [-0.7237,  0.1671, -0.0008],\n",
      "          [-0.1817,  1.1708,  0.5300]],\n",
      "\n",
      "         [[ 0.2645,  1.1454,  1.6934],\n",
      "          [-0.0582, -0.5861,  1.3110],\n",
      "          [-0.3479, -0.9814,  0.1526]],\n",
      "\n",
      "         [[-1.4726, -0.8433,  0.3236],\n",
      "          [ 0.1738,  0.4888,  0.1624],\n",
      "          [-0.7360, -0.6623, -0.3939]],\n",
      "\n",
      "         [[ 1.3607,  0.6224,  0.5630],\n",
      "          [ 0.5064, -0.7830,  0.2251],\n",
      "          [-0.2032, -0.7944, -1.3116]]]])\n"
     ]
    }
   ],
   "source": [
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6979)\n",
      "tensor([[[ 1.4651,  1.3050,  1.6934],\n",
      "         [ 0.9602,  2.5502,  1.3110],\n",
      "         [ 0.4767,  1.1708,  0.9175]]])\n",
      "torch.Size([1, 3, 3])\n",
      "tensor([[[ 4,  0,  6],\n",
      "         [ 1,  2,  6],\n",
      "         [ 1,  5,  3]]])\n",
      "1 3 3\n"
     ]
    }
   ],
   "source": [
    "d_max, d_max_index = torch.max(c1,1)\n",
    "print(c1[0,4,0,2])\n",
    "print(d_max)\n",
    "print(d_max_index.size())\n",
    "print(d_max_index)\n",
    "x,y,z = d_max.shape\n",
    "print(x,y,z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 1.,  0.,  0.],\n",
      "          [ 1.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  1.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  1.]],\n",
      "\n",
      "         [[ 1.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  1.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  1.],\n",
      "          [ 0.,  0.,  1.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]]]])\n",
      "torch.Size([1, 9, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "u = helper(c, 0.1)\n",
    "print(u)\n",
    "print(u.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 3, 3])\n",
      "torch.Size([1, 9, 3, 3])\n",
      "tensor([[[[-0.0000,  1.3050,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.9602, -0.0000,  0.0000],\n",
      "          [ 0.4767, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  2.5502, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.9175]],\n",
      "\n",
      "         [[ 1.4651, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  1.1708,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  1.6934],\n",
      "          [-0.0000, -0.0000,  1.3110],\n",
      "          [-0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "print(c1.size())\n",
    "print(u.size())\n",
    "print(torch.mul(c1,u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 3, 3])\n",
      "tensor([[[[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]]]])\n"
     ]
    }
   ],
   "source": [
    "t_zero = torch.zeros(1,9,3,3)\n",
    "print(t_zero.size())\n",
    "print(t_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.1290,  0.4124, -1.7386],\n",
      "          [-0.7921, -0.4450, -0.8708],\n",
      "          [ 0.4727, -0.4014,  1.2026]],\n",
      "\n",
      "         [[ 0.4062,  1.9689,  0.7067],\n",
      "          [-0.8952, -0.7421,  0.3678],\n",
      "          [-0.2262,  1.4510, -0.2578]],\n",
      "\n",
      "         [[ 1.0477, -1.0093, -0.5598],\n",
      "          [ 1.2956, -0.5233, -0.8708],\n",
      "          [ 0.1761, -0.9165, -0.1610]]]])\n"
     ]
    }
   ],
   "source": [
    "n = a[:,:,4,:,:]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524543037166\\work\\aten\\src\\th\\generic/THTensor.cpp:280",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-284-4e7892ca61c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524543037166\\work\\aten\\src\\th\\generic/THTensor.cpp:280"
     ]
    }
   ],
   "source": [
    "u = c.view(1,-1,9)\n",
    "print(u.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.rand(1,3,8,5,5)\n",
    "h.unsqeuze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
