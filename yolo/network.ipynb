{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 26+10+4   #Grossbuchstaben, Zahlen, {.:/-}\n",
    "anchors = [10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326]\n",
    "leaky_relu_value = 0.1\n",
    "anchor_number = np.size(anchors)/6\n",
    "features = int(anchor_number*(4+1+classes))\n",
    "dimension = 3\n",
    "ignore_thres = 0.7\n",
    "\n",
    "\n",
    "class Yolo_v3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Yolo_v3, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(dimension,32,3,stride=1,padding=1)\n",
    "        self.batch_1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(32,64,3,stride=2,padding=1)\n",
    "        self.batch_2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(64,32,1,stride=1,padding=0)\n",
    "        self.batch_3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv_4 = nn.Conv2d(32,64,3,stride=1,padding=1)\n",
    "        self.batch_4 = nn.BatchNorm2d(64)\n",
    "\n",
    "\n",
    "        \n",
    "        self.conv_6 = nn.Conv2d(64,128,3,stride=2,padding=1)\n",
    "        self.batch_6 = nn.BatchNorm2d(128)\n",
    "            \n",
    "        self.conv_7 = nn.Conv2d(128,64,1,stride=1,padding=0)\n",
    "        self.batch_7 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_8 = nn.Conv2d(64,128,3,stride=1,padding=1)\n",
    "        self.batch_8 = nn.BatchNorm2d(128)\n",
    " \n",
    "\n",
    "          \n",
    "        self.conv_10 = nn.Conv2d(128,64,1,stride=1,padding=0)\n",
    "        self.batch_10 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_11 = nn.Conv2d(64,128,3,stride=1,padding=1)\n",
    "        self.batch_11 = nn.BatchNorm2d(128)\n",
    "          \n",
    "\n",
    "             \n",
    "        self.conv_13 = nn.Conv2d(128,256,3,stride=2,padding=1)\n",
    "        self.batch_13 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_14 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_14 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_15 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_15 = nn.BatchNorm2d(256)        \n",
    "        \n",
    "\n",
    "\n",
    "        self.conv_17 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_17 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_18 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_18 = nn.BatchNorm2d(256)\n",
    "        \n",
    "       \n",
    "    \n",
    "        \n",
    "        self.conv_38 = nn.Conv2d(256,512,3,stride=2,padding=1)\n",
    "        self.batch_38 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_39 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_39 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_40 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_40 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_42 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_42 = nn.BatchNorm2d(256)        \n",
    "        \n",
    "        self.conv_43 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_43 = nn.BatchNorm2d(512)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.conv_63 = nn.Conv2d(512,1024,3,stride=2,padding=1)\n",
    "        self.batch_63 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv_64 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_64 = nn.BatchNorm2d(512)        \n",
    "        \n",
    "        self.conv_65 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_65 = nn.BatchNorm2d(1024)  \n",
    "        \n",
    "\n",
    "        \n",
    "        self.conv_67 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_67 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_68 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_68 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_76 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_76 = nn.BatchNorm2d(512)        \n",
    "        \n",
    "        self.conv_77 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_77 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv_82 = nn.Conv2d(1024,features,1,stride=1,padding=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_85 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_85 = nn.BatchNorm2d(256)       \n",
    "\n",
    "        self.convT_86 = nn.ConvTranspose2d(256,256,3,stride=2,padding=1,output_padding=1)\n",
    "        self.batch_86 = nn.BatchNorm2d(256) \n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv_88 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_88 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_89 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_89 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_94 = nn.Conv2d(512,features,1,stride=1,padding=0)\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        self.conv_97 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_97 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.convT_98 = nn.ConvTranspose2d(128,128,3,stride=2,padding=1,output_padding=1)\n",
    "        self.batch_98 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_100 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_100 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_101 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_101 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_106 = nn.Conv2d(256,features,1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        layer_1 = F.leaky_relu(self.batch_1(self.conv_1(inputs)),leaky_relu_value,True)\n",
    "        layer_2 = F.leaky_relu(self.batch_2(self.conv_2(layer_1)),leaky_relu_value,True)\n",
    "        layer_3 = F.leaky_relu(self.batch_3(self.conv_3(layer_2)),leaky_relu_value,True)\n",
    "        layer_4 = F.leaky_relu(self.batch_4(self.conv_4(layer_3)),leaky_relu_value,True)\n",
    "        layer_5 = layer_2 + layer_4\n",
    "        layer_6 = F.leaky_relu(self.batch_6(self.conv_6(layer_5)),leaky_relu_value,True)\n",
    "        layer_7 = F.leaky_relu(self.batch_7(self.conv_7(layer_6)),leaky_relu_value,True)\n",
    "        layer_8 = F.leaky_relu(self.batch_8(self.conv_8(layer_7)),leaky_relu_value,True)\n",
    "        layer_9 = layer_6 + layer_8\n",
    "        layer_10 = F.leaky_relu(self.batch_10(self.conv_10(layer_9)),leaky_relu_value,True)\n",
    "        layer_11 = F.leaky_relu(self.batch_11(self.conv_11(layer_10)),leaky_relu_value,True)\n",
    "        layer_12 = layer_9 + layer_11\n",
    "        layer_13 = F.leaky_relu(self.batch_13(self.conv_13(layer_12)),leaky_relu_value,True)\n",
    "        layer_14 = F.leaky_relu(self.batch_14(self.conv_14(layer_13)),leaky_relu_value,True)\n",
    "        layer_15 = F.leaky_relu(self.batch_15(self.conv_15(layer_14)),leaky_relu_value,True)\n",
    "        layer_16 = layer_13 + layer_15\n",
    "        layer_17 = F.leaky_relu(self.batch_17(self.conv_17(layer_16)),leaky_relu_value,True)\n",
    "        layer_18 = F.leaky_relu(self.batch_18(self.conv_18(layer_17)),leaky_relu_value,True)\n",
    "        layer_19 = layer_16 + layer_18      \n",
    "        layer_20 = F.leaky_relu(self.batch_17(self.conv_17(layer_19)),leaky_relu_value,True)\n",
    "        layer_21 = F.leaky_relu(self.batch_18(self.conv_18(layer_20)),leaky_relu_value,True)\n",
    "        layer_22 = layer_19 + layer_21\n",
    "        layer_23 = F.leaky_relu(self.batch_17(self.conv_17(layer_22)),leaky_relu_value,True)\n",
    "        layer_24 = F.leaky_relu(self.batch_18(self.conv_18(layer_23)),leaky_relu_value,True)\n",
    "        layer_25 = layer_22 + layer_24\n",
    "        layer_26 = F.leaky_relu(self.batch_17(self.conv_17(layer_25)),leaky_relu_value,True)\n",
    "        layer_27 = F.leaky_relu(self.batch_18(self.conv_18(layer_26)),leaky_relu_value,True)\n",
    "        layer_28 = layer_25 + layer_27\n",
    "        layer_29 = F.leaky_relu(self.batch_17(self.conv_17(layer_28)),leaky_relu_value,True)\n",
    "        layer_30 = F.leaky_relu(self.batch_18(self.conv_18(layer_29)),leaky_relu_value,True)\n",
    "        layer_31 = layer_28 + layer_30\n",
    "        layer_32 = F.leaky_relu(self.batch_17(self.conv_17(layer_31)),leaky_relu_value,True)\n",
    "        layer_33 = F.leaky_relu(self.batch_18(self.conv_18(layer_32)),leaky_relu_value,True)\n",
    "        layer_34 = layer_31 + layer_33\n",
    "        layer_35 = F.leaky_relu(self.batch_17(self.conv_17(layer_34)),leaky_relu_value,True)\n",
    "        layer_36 = F.leaky_relu(self.batch_18(self.conv_18(layer_35)),leaky_relu_value,True)\n",
    "        layer_37 = layer_34 + layer_36\n",
    "        layer_38 = F.leaky_relu(self.batch_38(self.conv_38(layer_37)),leaky_relu_value,True)\n",
    "        layer_39 = F.leaky_relu(self.batch_39(self.conv_39(layer_38)),leaky_relu_value,True)\n",
    "        layer_40 = F.leaky_relu(self.batch_40(self.conv_40(layer_39)),leaky_relu_value,True)\n",
    "        layer_41 = layer_38 + layer_40\n",
    "        layer_42 = F.leaky_relu(self.batch_42(self.conv_42(layer_41)),leaky_relu_value,True)\n",
    "        layer_43 = F.leaky_relu(self.batch_43(self.conv_43(layer_42)),leaky_relu_value,True)\n",
    "        layer_44 = layer_41 + layer_43\n",
    "        layer_45 = F.leaky_relu(self.batch_42(self.conv_42(layer_44)),leaky_relu_value,True)\n",
    "        layer_46 = F.leaky_relu(self.batch_43(self.conv_43(layer_45)),leaky_relu_value,True)\n",
    "        layer_47 = layer_44 + layer_46\n",
    "        layer_48 = F.leaky_relu(self.batch_42(self.conv_42(layer_47)),leaky_relu_value,True)\n",
    "        layer_49 = F.leaky_relu(self.batch_43(self.conv_43(layer_48)),leaky_relu_value,True)\n",
    "        layer_50 = layer_47 + layer_49\n",
    "        layer_51 = F.leaky_relu(self.batch_42(self.conv_42(layer_50)),leaky_relu_value,True)\n",
    "        layer_52 = F.leaky_relu(self.batch_43(self.conv_43(layer_51)),leaky_relu_value,True)\n",
    "        layer_53 = layer_50 + layer_52\n",
    "        layer_54 = F.leaky_relu(self.batch_42(self.conv_42(layer_53)),leaky_relu_value,True)\n",
    "        layer_55 = F.leaky_relu(self.batch_43(self.conv_43(layer_54)),leaky_relu_value,True)\n",
    "        layer_56 = layer_53 +layer_55\n",
    "        layer_57 = F.leaky_relu(self.batch_42(self.conv_42(layer_56)),leaky_relu_value,True)\n",
    "        layer_58 = F.leaky_relu(self.batch_43(self.conv_43(layer_57)),leaky_relu_value,True)\n",
    "        layer_59 = layer_56 + layer_58\n",
    "        layer_60 = F.leaky_relu(self.batch_42(self.conv_42(layer_59)),leaky_relu_value,True)\n",
    "        layer_61 = F.leaky_relu(self.batch_43(self.conv_43(layer_60)),leaky_relu_value,True)\n",
    "        layer_62 = layer_59 + layer_61\n",
    "        layer_63 = F.leaky_relu(self.batch_63(self.conv_63(layer_62)),leaky_relu_value,True)\n",
    "        layer_64 = F.leaky_relu(self.batch_64(self.conv_64(layer_63)),leaky_relu_value,True)\n",
    "        layer_65 = F.leaky_relu(self.batch_65(self.conv_65(layer_64)),leaky_relu_value,True)\n",
    "        layer_66 = layer_63 + layer_65\n",
    "        layer_67 = F.leaky_relu(self.batch_67(self.conv_67(layer_66)),leaky_relu_value,True)\n",
    "        layer_68 = F.leaky_relu(self.batch_68(self.conv_68(layer_67)),leaky_relu_value,True)\n",
    "        layer_69 = layer_66 + layer_68\n",
    "        layer_70 = F.leaky_relu(self.batch_67(self.conv_67(layer_69)),leaky_relu_value,True)\n",
    "        layer_71 = F.leaky_relu(self.batch_68(self.conv_68(layer_70)),leaky_relu_value,True)\n",
    "        layer_72 = layer_69 + layer_71\n",
    "        layer_73 = F.leaky_relu(self.batch_67(self.conv_67(layer_72)),leaky_relu_value,True)\n",
    "        layer_74 = F.leaky_relu(self.batch_68(self.conv_68(layer_73)),leaky_relu_value,True)\n",
    "        layer_75 = layer_72 + layer_74\n",
    "        layer_76 = F.leaky_relu(self.batch_76(self.conv_76(layer_75)),leaky_relu_value,True)\n",
    "        layer_77 = F.leaky_relu(self.batch_77(self.conv_77(layer_76)),leaky_relu_value,True)\n",
    "        layer_78 = F.leaky_relu(self.batch_76(self.conv_76(layer_77)),leaky_relu_value,True)\n",
    "        layer_79 = F.leaky_relu(self.batch_77(self.conv_77(layer_78)),leaky_relu_value,True)\n",
    "        layer_80 = F.leaky_relu(self.batch_76(self.conv_76(layer_79)),leaky_relu_value,True)\n",
    "        layer_81 = F.leaky_relu(self.batch_77(self.conv_77(layer_80)),leaky_relu_value,True)\n",
    "        layer_82 = self.conv_82(layer_81)\n",
    "        layer_83 = layer_82\n",
    "        layer_84 = layer_80   # 16x16\n",
    "        layer_85 = F.leaky_relu(self.batch_85(self.conv_85(layer_84)),leaky_relu_value,True)\n",
    "        layer_86 = F.leaky_relu(self.batch_86(self.convT_86(layer_85)),leaky_relu_value,True)\n",
    "        layer_87 = torch.cat((layer_60,layer_86),1)\n",
    "        layer_88 = F.leaky_relu(self.batch_88(self.conv_88(layer_87)),leaky_relu_value,True)\n",
    "        layer_89 = F.leaky_relu(self.batch_89(self.conv_89(layer_88)),leaky_relu_value,True)\n",
    "        layer_90 = F.leaky_relu(self.batch_88(self.conv_88(layer_89)),leaky_relu_value,True)\n",
    "        layer_91 = F.leaky_relu(self.batch_89(self.conv_89(layer_90)),leaky_relu_value,True)\n",
    "        layer_92 = F.leaky_relu(self.batch_88(self.conv_88(layer_91)),leaky_relu_value,True)\n",
    "        layer_93 = F.leaky_relu(self.batch_89(self.conv_89(layer_92)),leaky_relu_value,True)\n",
    "        layer_94 = self.conv_94(layer_93)\n",
    "        layer_95 = layer_94\n",
    "        layer_96 = layer_92   # 32x32\n",
    "        layer_97 = F.leaky_relu(self.batch_97(self.conv_97(layer_96)),leaky_relu_value,True)\n",
    "        layer_98 = F.leaky_relu(self.batch_98(self.convT_98(layer_97)),leaky_relu_value,True)\n",
    "        layer_99 = torch.cat((layer_35,layer_98),1)\n",
    "        layer_100 = F.leaky_relu(self.batch_100(self.conv_100(layer_99)),leaky_relu_value,True)\n",
    "        layer_101 = F.leaky_relu(self.batch_101(self.conv_101(layer_100)),leaky_relu_value,True)\n",
    "        layer_102 = F.leaky_relu(self.batch_100(self.conv_100(layer_101)),leaky_relu_value,True)\n",
    "        layer_103 = F.leaky_relu(self.batch_101(self.conv_101(layer_102)),leaky_relu_value,True)\n",
    "        layer_104 = F.leaky_relu(self.batch_100(self.conv_100(layer_103)),leaky_relu_value,True)\n",
    "        layer_105 = F.leaky_relu(self.batch_101(self.conv_101(layer_104)),leaky_relu_value,True)\n",
    "        layer_106 = self.conv_106(layer_105)\n",
    "        layer_107 = layer_106   # 64x64\n",
    "        return layer_83, layer_95, layer_106   # ...*3*(5+26+10+4) = 135\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yolo_v3(\n",
      "  (conv_1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_7): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_10): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_13): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_14): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_15): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_17): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_18): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_38): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_39): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_39): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_40): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_42): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_42): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_43): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_63): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_63): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_64): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_65): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_65): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_67): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_68): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_68): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_76): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_76): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_77): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_77): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_82): Conv2d(1024, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_85): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_85): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (convT_86): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (batch_86): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_88): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_88): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_89): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_89): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_94): Conv2d(512, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_97): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_97): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (convT_98): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (batch_98): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_100): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_100): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_101): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_101): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_106): Conv2d(256, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Yolo_v3()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 135, 16, 16]) torch.Size([1, 135, 32, 32]) torch.Size([1, 135, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 512, 512)\n",
    "output_layer_1, output_layer_2, output_layer_3 = net(x)\n",
    "print(output_layer_1.size(),output_layer_2.size(),output_layer_3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer_dim(output_layer):\n",
    "    batch_number, outputs, y, x = output_layer.shape\n",
    "    return output_layer_1.view(batch_number, anchor_number, 5, outputs/5/anchor_number, y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 9, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(output_layer_dim(output_layer_1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: yolo_filter_boxes\n",
    "\n",
    "def yolo_filter_boxes(output_layer, ignore_thresh  = 0.7):\n",
    "    \"\"\"Filters YOLO boxes by thresholding on object and class confidence.\n",
    "    \n",
    "    Arguments:\n",
    "    box_confidence -- tensor of shape (19, 19, 5, 1)   (1,anchor_number,1,y,x)\n",
    "    boxes -- tensor of shape (19, 19, 5, 4)   (1,anchor_number,4,y,x)\n",
    "    box_class_probs -- tensor of shape (19, 19, 5, 80)   (1,anchor_number,classes,y,x)\n",
    "    threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None,), containing the class probability score for selected boxes\n",
    "    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes\n",
    "    classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes\n",
    "    \n",
    "    Note: \"None\" is here because you don't know the exact number of selected boxes, as it depends on the threshold. \n",
    "    For example, the actual output size of scores would be (10,) if there are 10 boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    box_confidence = output_layer\n",
    "    box_confidence[:,:,0<ingore_tresh,:,:] = 0\n",
    "    \n",
    "    # Step 1: Compute box scores\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    box_scores = box_confidence[:,:,0,:,:,:] * box_class_probs[:,:,:,:,:,:] # 19x19x80   1,3,1,x,y * 1,3,\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 2: Find the box_classes thanks to the max box_scores, keep track of the corresponding score\n",
    "    ### START CODE HERE ### (≈ 2 lines)\n",
    "    box_classes = K.argmax(box_scores, axis = -1)  # 19x19x5x1  (1 class index)\n",
    "    box_class_scores = K.max(box_scores, axis = -1)  # 19x19x5x1 (1 class score)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 3: Create a filtering mask based on \"box_class_scores\" by using \"threshold\". The mask should have the\n",
    "    # same dimension as box_class_scores, and be True for the boxes you want to keep (with probability >= threshold)\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    filtering_mask = box_class_scores >= threshold\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 4: Apply the mask to scores, boxes and classes\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24])\n",
      "tensor([[-0.0648,  0.7843,  0.1301, -0.4658,  0.1693,  0.8792,  1.3256,\n",
      "         -0.2433, -0.1955, -1.3749,  1.2619,  0.1159,  0.9152, -1.4587,\n",
      "          0.2737, -0.5083,  1.0659, -1.1094,  0.9076,  1.1037, -0.3661,\n",
      "         -0.5086, -1.0312, -0.7361]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,24)\n",
    "print(a.size())\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 8])\n",
      "tensor([[[-0.0648,  0.7843,  0.1301, -0.4658,  0.1693,  0.8792,  1.3256,\n",
      "          -0.2433],\n",
      "         [-0.1955, -1.3749,  1.2619,  0.1159,  0.9152, -1.4587,  0.2737,\n",
      "          -0.5083],\n",
      "         [ 1.0659, -1.1094,  0.9076,  1.1037, -0.3661, -0.5086, -1.0312,\n",
      "          -0.7361]]])\n"
     ]
    }
   ],
   "source": [
    "b = a.view(1,3,8)\n",
    "print(b.size())\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([1, 1, 12, 12])\n",
      "b:  torch.Size([1, 1, 6, 6])\n",
      "c:  torch.Size([1, 1, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,1,12,12)\n",
    "conv = nn.Conv2d(1,1,3, stride=2,padding=1)\n",
    "convT = nn.ConvTranspose2d(1,1,3,stride=2,padding=0)\n",
    "\n",
    "b = conv(a)\n",
    "c = convT(b)\n",
    "\n",
    "print(\"a: \", a.size())\n",
    "print(\"b: \", b.size())\n",
    "print(\"c: \", c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d:  torch.Size([1, 1, 6, 6])\n",
      "ConvTranspose2d:  torch.Size([1, 1, 24, 24])\n",
      "Conv2d und ConvTranspose2d:  torch.Size([1, 1, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1, 1, 12, 12)   # Batch, Anzahl channels, X,Y \n",
    "downsample = nn.Conv2d(1, 1, 3, stride=2, padding=1)\n",
    "upsample = nn.ConvTranspose2d(1, 1, 3, stride=2, padding=1,output_padding=1)\n",
    "h = downsample(inputs)\n",
    "print('Conv2d: ', h.size())        # (1, 1, 6, 6)\n",
    "output = upsample(inputs)\n",
    "print('ConvTranspose2d: ', output.size())    # (1, 1, 12, 12)\n",
    "g = upsample(h)\n",
    "print('Conv2d und ConvTranspose2d: ', g.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 16, 16])\n",
      "torch.Size([1, 3, 40, 16, 16])\n",
      "torch.Size([1, 3, 40, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,45,16,16)\n",
    "b = torch.randn(1,3,45,16,16)\n",
    "a_1 = a[:,:,0:1,:,:]\n",
    "b_1 = b[:,:,5:45,:,:]\n",
    "print(a_1.size())\n",
    "print(b_1.size())\n",
    "c = a_1 * b_1\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-0.5632,  0.6375,  0.1176],\n",
      "           [ 0.5447, -1.1462,  0.1490],\n",
      "           [-0.1251, -0.1474, -1.1917]],\n",
      "\n",
      "          [[ 1.4222, -0.1715,  0.7544],\n",
      "           [-0.8280, -0.9577, -0.3616],\n",
      "           [-0.0319,  1.7941,  1.0353]],\n",
      "\n",
      "          [[ 0.6186,  2.3321,  1.5046],\n",
      "           [-1.1668,  0.9314, -1.3445],\n",
      "           [ 1.7020, -2.2355, -0.1922]],\n",
      "\n",
      "          [[ 1.1037, -1.1261,  1.2690],\n",
      "           [-0.1766, -0.5015, -1.4852],\n",
      "           [-0.7359,  0.4979, -1.5330]],\n",
      "\n",
      "          [[-1.2854, -0.4633,  0.6230],\n",
      "           [ 0.5019,  0.0472,  1.4350],\n",
      "           [-0.6152, -0.0931,  1.0234]],\n",
      "\n",
      "          [[-1.6129,  0.4488, -0.4820],\n",
      "           [-1.1157,  0.1372, -1.3236],\n",
      "           [-1.5912, -2.2227, -0.2241]],\n",
      "\n",
      "          [[ 0.5580, -1.1875,  0.6929],\n",
      "           [ 0.7481,  0.0935, -1.2490],\n",
      "           [-0.3822, -2.0549, -0.5237]],\n",
      "\n",
      "          [[-0.3973,  0.3810,  0.8703],\n",
      "           [-1.0691, -1.7368, -1.3901],\n",
      "           [ 0.7283,  0.8566,  0.8124]]],\n",
      "\n",
      "\n",
      "         [[[-0.0612,  0.9618, -0.3454],\n",
      "           [-0.6440, -0.5219,  1.6592],\n",
      "           [ 0.2547, -0.0360,  0.8362]],\n",
      "\n",
      "          [[ 1.1599, -1.0799, -0.0946],\n",
      "           [-0.5724, -0.8783,  1.4978],\n",
      "           [ 1.9730, -0.6517,  0.3818]],\n",
      "\n",
      "          [[-0.8657,  1.6474, -0.0236],\n",
      "           [ 0.4914, -0.8845, -0.4954],\n",
      "           [ 0.3094,  1.4308,  0.6290]],\n",
      "\n",
      "          [[ 0.5496, -0.3941, -1.0050],\n",
      "           [-1.2025, -0.9625,  3.5999],\n",
      "           [-0.8817, -1.0656,  1.2344]],\n",
      "\n",
      "          [[ 0.8667,  1.0035,  0.2771],\n",
      "           [-0.7853, -0.2350,  0.6939],\n",
      "           [-0.7028,  0.1995,  2.1824]],\n",
      "\n",
      "          [[-0.2028,  0.1187, -0.8554],\n",
      "           [ 1.1300,  0.3336,  0.6333],\n",
      "           [ 0.7094, -1.9753, -0.3694]],\n",
      "\n",
      "          [[-2.6496,  0.6344, -1.2281],\n",
      "           [-0.2903, -1.3730,  0.8903],\n",
      "           [ 0.0646, -0.1108, -0.6684]],\n",
      "\n",
      "          [[ 1.5021,  1.4429, -0.3047],\n",
      "           [-0.2504, -0.7102,  0.8417],\n",
      "           [ 2.7909,  0.2577, -0.6023]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4032,  0.5624, -1.3425],\n",
      "           [ 1.1347, -1.3322,  0.0520],\n",
      "           [-0.5015,  0.6539, -0.4596]],\n",
      "\n",
      "          [[-0.6097, -1.3807, -1.4273],\n",
      "           [ 0.7307, -0.4447,  0.4197],\n",
      "           [ 0.3383, -1.2180,  1.4079]],\n",
      "\n",
      "          [[-1.0507, -0.8582, -1.5619],\n",
      "           [-1.3115, -0.5419,  1.1295],\n",
      "           [ 0.6709,  1.0720,  0.3408]],\n",
      "\n",
      "          [[-0.2866,  0.3248,  1.1518],\n",
      "           [-0.0245, -1.0488,  1.2050],\n",
      "           [ 0.9960, -1.5708, -0.0846]],\n",
      "\n",
      "          [[ 0.8928,  1.2801, -0.7385],\n",
      "           [-0.2973,  1.4566, -0.7409],\n",
      "           [ 0.2575,  0.6774,  1.2078]],\n",
      "\n",
      "          [[-0.0457,  0.2903,  2.3342],\n",
      "           [-0.0829, -1.5931,  1.2346],\n",
      "           [-0.7915,  1.8921, -0.0874]],\n",
      "\n",
      "          [[ 0.0110, -0.3751,  1.7428],\n",
      "           [-0.2006, -0.6385, -0.0361],\n",
      "           [ 1.7169,  0.5081,  0.9622]],\n",
      "\n",
      "          [[-0.2139, -0.2730,  0.2823],\n",
      "           [ 0.4141, -0.3532, -0.0470],\n",
      "           [-1.2433,  0.3206,  0.0021]]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,8,3,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.5632,  0.6375,  0.1176],\n",
      "          [ 0.5447, -1.1462,  0.1490],\n",
      "          [-0.1251, -0.1474, -1.1917]],\n",
      "\n",
      "         [[-0.0612,  0.9618, -0.3454],\n",
      "          [-0.6440, -0.5219,  1.6592],\n",
      "          [ 0.2547, -0.0360,  0.8362]],\n",
      "\n",
      "         [[ 0.4032,  0.5624, -1.3425],\n",
      "          [ 1.1347, -1.3322,  0.0520],\n",
      "          [-0.5015,  0.6539, -0.4596]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a[:,:,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_output[:,:,0,:,:] => pc\n",
    "# layer_output[:,:,1,:,:] => bx\n",
    "# layer_output[:,:,2,:,:] => by\n",
    "# layer_output[:,:,3,:,:] => tx\n",
    "# layer_output[:,:,4,:,:] => ty\n",
    "# layer_output[:,:,5,:,:] => c1\n",
    "# layer_output[:,:,n,:,:] => cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-1.6129,  0.4488, -0.4820],\n",
      "           [-1.1157,  0.1372, -1.3236],\n",
      "           [-1.5912, -2.2227, -0.2241]],\n",
      "\n",
      "          [[ 0.5580, -1.1875,  0.6929],\n",
      "           [ 0.7481,  0.0935, -1.2490],\n",
      "           [-0.3822, -2.0549, -0.5237]],\n",
      "\n",
      "          [[-0.3973,  0.3810,  0.8703],\n",
      "           [-1.0691, -1.7368, -1.3901],\n",
      "           [ 0.7283,  0.8566,  0.8124]]],\n",
      "\n",
      "\n",
      "         [[[-0.2028,  0.1187, -0.8554],\n",
      "           [ 1.1300,  0.3336,  0.6333],\n",
      "           [ 0.7094, -1.9753, -0.3694]],\n",
      "\n",
      "          [[-2.6496,  0.6344, -1.2281],\n",
      "           [-0.2903, -1.3730,  0.8903],\n",
      "           [ 0.0646, -0.1108, -0.6684]],\n",
      "\n",
      "          [[ 1.5021,  1.4429, -0.3047],\n",
      "           [-0.2504, -0.7102,  0.8417],\n",
      "           [ 2.7909,  0.2577, -0.6023]]],\n",
      "\n",
      "\n",
      "         [[[-0.0457,  0.2903,  2.3342],\n",
      "           [-0.0829, -1.5931,  1.2346],\n",
      "           [-0.7915,  1.8921, -0.0874]],\n",
      "\n",
      "          [[ 0.0110, -0.3751,  1.7428],\n",
      "           [-0.2006, -0.6385, -0.0361],\n",
      "           [ 1.7169,  0.5081,  0.9622]],\n",
      "\n",
      "          [[-0.2139, -0.2730,  0.2823],\n",
      "           [ 0.4141, -0.3532, -0.0470],\n",
      "           [-1.2433,  0.3206,  0.0021]]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a[:,:,5:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_surpression(layer_output, ignore_threshold = 0.7):\n",
    "    box_scores = torch.mul(layer_output[:,:,5:,:,:], layer_output[:,:,0,:,:]) # confidence * class score\n",
    "    torch.cat((c[:,0,:,:,:], c[:,1,:,:,:], c[:,2,:,:,:]),1)\n",
    "    return box_scores\n",
    "\n",
    "    # class_scores = torch.mul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,8,3,3)\n",
    "b = non_max_surpression(a,0.7)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n",
      "tensor([[[[[-1.1322,  0.0582, -0.0783],\n",
      "           [ 0.1537, -0.2537,  0.0696],\n",
      "           [-1.8338,  0.8620, -1.2413]],\n",
      "\n",
      "          [[-0.7102, -0.4030, -0.1584],\n",
      "           [ 0.5782, -0.1731,  0.6507],\n",
      "           [ 0.0943, -0.6497,  0.1862]],\n",
      "\n",
      "          [[ 0.4290,  1.6862,  0.0593],\n",
      "           [ 0.1548,  0.3242, -0.0112],\n",
      "           [ 1.2507,  1.4523, -0.1174]]],\n",
      "\n",
      "\n",
      "         [[[ 0.8571, -0.2422, -0.7888],\n",
      "           [ 0.1674,  0.1334,  4.1811],\n",
      "           [ 5.1975,  1.1366, -0.7760]],\n",
      "\n",
      "          [[-0.0089,  0.5696, -0.0306],\n",
      "           [-1.3017, -0.3081,  0.8529],\n",
      "           [ 0.1151, -3.7696,  0.5952]],\n",
      "\n",
      "          [[-0.2694, -0.1435, -0.3717],\n",
      "           [-0.4499,  0.6509,  0.0265],\n",
      "           [-1.2660, -1.4730, -0.6306]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5426,  0.0043,  1.8324],\n",
      "           [-1.3500,  0.2663,  0.3317],\n",
      "           [ 0.3866,  0.1965,  0.4595]],\n",
      "\n",
      "          [[-2.7343, -0.4323, -1.5813],\n",
      "           [ 0.0145,  0.9664,  0.8758],\n",
      "           [-0.1254,  1.7350, -0.2531]],\n",
      "\n",
      "          [[-0.0274, -0.0950,  1.4049],\n",
      "           [-0.1042,  0.3156,  0.0785],\n",
      "           [ 0.7220,  1.0007, -0.3720]]]]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.mul(a[:,:,5:,:,:], a[:,:,0,:,:])\n",
    "print(b.size())\n",
    "# b[b<0.1] = 0\n",
    "# b[b>=0.1] = 1\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   box_classes = K.argmax(box_scores, axis = -1)  # 19x19x5x1  (1 class index)\n",
    "#  box_class_scores = K.max(box_scores, axis = -1)  # 19x19x5x1 (1 class score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0.1220, -2.3077,  1.0147],\n",
      "           [ 1.3545,  0.2186,  0.2549],\n",
      "           [-0.9341, -0.3405,  0.2534]],\n",
      "\n",
      "          [[-0.3934,  0.2323,  1.0079],\n",
      "           [-0.7233,  0.3510,  0.1820],\n",
      "           [ 1.9448, -0.0139,  1.8568]],\n",
      "\n",
      "          [[-0.8234,  0.7569,  1.2726],\n",
      "           [ 0.0531,  0.3072, -1.6738],\n",
      "           [-0.4222, -0.8036, -0.9599]],\n",
      "\n",
      "          [[-1.9957,  0.5332, -0.7662],\n",
      "           [-0.2578, -0.1559,  0.1012],\n",
      "           [-0.0021,  0.2443, -0.1736]],\n",
      "\n",
      "          [[-0.3769,  0.3099, -0.3767],\n",
      "           [ 0.9824, -0.5263,  2.4689],\n",
      "           [ 0.4992, -0.9548, -0.2866]],\n",
      "\n",
      "          [[ 0.2438,  1.0884,  0.1553],\n",
      "           [ 0.0204, -1.0997, -0.1462],\n",
      "           [-0.1390,  1.3436,  0.7761]],\n",
      "\n",
      "          [[ 1.8315,  0.1693, -0.4454],\n",
      "           [ 1.2005, -1.0768, -0.1584],\n",
      "           [-1.6010,  0.8415, -0.1560]],\n",
      "\n",
      "          [[-0.0628,  0.9275,  0.6495],\n",
      "           [ 0.9526, -0.5289, -0.3398],\n",
      "           [ 0.7091, -1.6005,  1.4025]]],\n",
      "\n",
      "\n",
      "         [[[-0.2598,  0.0902, -0.8940],\n",
      "           [-0.0996,  1.0472, -0.2915],\n",
      "           [ 1.9742,  1.2278,  2.3927]],\n",
      "\n",
      "          [[ 0.8503,  0.1451,  0.8228],\n",
      "           [-1.0220, -2.5065,  0.2574],\n",
      "           [-1.1855,  1.1007, -0.1318]],\n",
      "\n",
      "          [[ 0.2946, -1.6787,  0.7438],\n",
      "           [ 0.3778,  0.7638, -0.1644],\n",
      "           [-1.8939,  0.5094,  0.5742]],\n",
      "\n",
      "          [[ 0.3723,  0.6296, -0.0056],\n",
      "           [-0.6764, -0.5391, -0.6048],\n",
      "           [ 1.6238,  0.0271, -0.5221]],\n",
      "\n",
      "          [[-0.5856,  0.2229, -0.2638],\n",
      "           [ 1.1614,  0.0417,  1.5456],\n",
      "           [-0.6209, -0.2642, -0.1882]],\n",
      "\n",
      "          [[-0.2818,  0.0377,  0.1103],\n",
      "           [ 0.4237, -2.8431, -0.2450],\n",
      "           [ 1.1852,  0.0919, -0.5272]],\n",
      "\n",
      "          [[-1.0208,  0.4393,  1.1232],\n",
      "           [ 0.2400,  1.2884,  1.0739],\n",
      "           [-0.0562,  0.4998, -1.3173]],\n",
      "\n",
      "          [[-1.9646,  0.6473,  1.0885],\n",
      "           [ 0.8605,  0.6935, -0.4149],\n",
      "           [ 0.3490,  2.4854,  0.4835]]],\n",
      "\n",
      "\n",
      "         [[[-0.7296, -0.7264,  2.0177],\n",
      "           [-0.5359, -0.5523, -0.4779],\n",
      "           [-0.0092, -0.5568,  0.6620]],\n",
      "\n",
      "          [[-0.2793,  0.3125, -1.6567],\n",
      "           [ 0.6717,  1.3380, -1.5984],\n",
      "           [ 0.2477,  1.7530, -1.6799]],\n",
      "\n",
      "          [[ 0.1992, -1.5971,  0.7475],\n",
      "           [-1.7818,  1.1737,  0.9896],\n",
      "           [ 0.5511, -1.3107,  0.3488]],\n",
      "\n",
      "          [[ 0.5845,  1.0633,  0.0596],\n",
      "           [ 1.0773,  0.1737,  0.7193],\n",
      "           [-0.4952,  0.5014, -0.2516]],\n",
      "\n",
      "          [[ 0.7777, -0.1419,  1.3183],\n",
      "           [-0.9632,  0.2173, -0.7363],\n",
      "           [ 0.3123, -1.5836,  0.4472]],\n",
      "\n",
      "          [[-1.4943, -0.0180,  2.1912],\n",
      "           [-0.0264,  0.7860,  0.5635],\n",
      "           [ 1.0275,  0.1464, -0.2118]],\n",
      "\n",
      "          [[ 1.4158, -1.5230, -0.5417],\n",
      "           [-1.9346,  0.9279, -1.7779],\n",
      "           [ 1.0084,  0.3952,  0.1662]],\n",
      "\n",
      "          [[-1.2135, -2.0783,  0.0837],\n",
      "           [ 2.1717, -0.4469, -0.2638],\n",
      "           [-0.3126, -0.1465,  0.6101]]]]])\n",
      "torch.Size([9, 24])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,8,3,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-0.6993, -0.2940, -0.4772],\n",
      "           [ 1.4565, -0.4373,  0.9979],\n",
      "           [-0.8052, -0.4636, -2.1821]],\n",
      "\n",
      "          [[-0.8511,  0.5093, -0.6805],\n",
      "           [ 0.4547, -0.0038,  1.9686],\n",
      "           [-0.2612, -0.7530, -0.4427]],\n",
      "\n",
      "          [[ 0.7497, -0.0539,  1.0898],\n",
      "           [-1.2282,  0.5399, -0.3640],\n",
      "           [-0.2050,  0.7630,  0.6703]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1414,  0.8751,  1.5499],\n",
      "           [-0.3395,  0.3645,  0.5851],\n",
      "           [-0.9213, -0.7492,  0.4664]],\n",
      "\n",
      "          [[-0.4165,  0.5498,  0.7786],\n",
      "           [ 1.6693,  0.4224,  0.8212],\n",
      "           [-0.7727,  1.9343, -1.0211]],\n",
      "\n",
      "          [[ 0.7504, -0.7099, -1.1008],\n",
      "           [-0.2859, -0.9859,  0.3521],\n",
      "           [-1.1357, -0.9136, -1.4898]]],\n",
      "\n",
      "\n",
      "         [[[-0.0297,  0.0597,  0.7610],\n",
      "           [-1.1420, -1.0820, -0.8292],\n",
      "           [-0.0726,  0.9336, -0.1680]],\n",
      "\n",
      "          [[ 0.5487, -0.6879, -0.9267],\n",
      "           [-1.1486,  1.7770,  0.1040],\n",
      "           [-0.2390, -0.8944,  0.2208]],\n",
      "\n",
      "          [[-0.3085, -0.7748, -1.6080],\n",
      "           [-0.2219,  0.0502,  0.4931],\n",
      "           [-0.5458, -1.6256,  0.5277]]]]])\n"
     ]
    }
   ],
   "source": [
    "c = a[:,:,5:,:,:]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n",
      "torch.Size([1, 9, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "c1 = torch.cat((c[:,0,:,:,:], c[:,1,:,:,:], c[:,2,:,:,:]),1)\n",
    "print(c.size())\n",
    "print(c1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.6993, -0.2940, -0.4772],\n",
      "          [ 1.4565, -0.4373,  0.9979],\n",
      "          [-0.8052, -0.4636, -2.1821]],\n",
      "\n",
      "         [[-0.8511,  0.5093, -0.6805],\n",
      "          [ 0.4547, -0.0038,  1.9686],\n",
      "          [-0.2612, -0.7530, -0.4427]],\n",
      "\n",
      "         [[ 0.7497, -0.0539,  1.0898],\n",
      "          [-1.2282,  0.5399, -0.3640],\n",
      "          [-0.2050,  0.7630,  0.6703]],\n",
      "\n",
      "         [[ 0.1414,  0.8751,  1.5499],\n",
      "          [-0.3395,  0.3645,  0.5851],\n",
      "          [-0.9213, -0.7492,  0.4664]],\n",
      "\n",
      "         [[-0.4165,  0.5498,  0.7786],\n",
      "          [ 1.6693,  0.4224,  0.8212],\n",
      "          [-0.7727,  1.9343, -1.0211]],\n",
      "\n",
      "         [[ 0.7504, -0.7099, -1.1008],\n",
      "          [-0.2859, -0.9859,  0.3521],\n",
      "          [-1.1357, -0.9136, -1.4898]],\n",
      "\n",
      "         [[-0.0297,  0.0597,  0.7610],\n",
      "          [-1.1420, -1.0820, -0.8292],\n",
      "          [-0.0726,  0.9336, -0.1680]],\n",
      "\n",
      "         [[ 0.5487, -0.6879, -0.9267],\n",
      "          [-1.1486,  1.7770,  0.1040],\n",
      "          [-0.2390, -0.8944,  0.2208]],\n",
      "\n",
      "         [[-0.3085, -0.7748, -1.6080],\n",
      "          [-0.2219,  0.0502,  0.4931],\n",
      "          [-0.5458, -1.6256,  0.5277]]]])\n"
     ]
    }
   ],
   "source": [
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.7504,  0.8751,  1.5499],\n",
      "         [ 1.6693,  1.7770,  1.9686],\n",
      "         [-0.0726,  1.9343,  0.6703]]])\n",
      "torch.Size([1, 3, 3])\n",
      "tensor([[[ 5,  3,  3],\n",
      "         [ 4,  7,  1],\n",
      "         [ 6,  4,  2]]])\n"
     ]
    }
   ],
   "source": [
    "d_max, d_max_index = torch.max(c1,1)\n",
    "print(d_max)\n",
    "print(d_max_index.size())\n",
    "print(d_max_index)\n",
    "print(c_max_index[:.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 3, 3])\n",
      "tensor([[[[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]]]])\n"
     ]
    }
   ],
   "source": [
    "t_zero = torch.zeros(1,9,3,3)\n",
    "print(t_zero.size())\n",
    "print(t_zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.1290,  0.4124, -1.7386],\n",
      "          [-0.7921, -0.4450, -0.8708],\n",
      "          [ 0.4727, -0.4014,  1.2026]],\n",
      "\n",
      "         [[ 0.4062,  1.9689,  0.7067],\n",
      "          [-0.8952, -0.7421,  0.3678],\n",
      "          [-0.2262,  1.4510, -0.2578]],\n",
      "\n",
      "         [[ 1.0477, -1.0093, -0.5598],\n",
      "          [ 1.2956, -0.5233, -0.8708],\n",
      "          [ 0.1761, -0.9165, -0.1610]]]])\n"
     ]
    }
   ],
   "source": [
    "n = a[:,:,4,:,:]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524543037166\\work\\aten\\src\\th\\generic/THTensor.cpp:280",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-284-4e7892ca61c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524543037166\\work\\aten\\src\\th\\generic/THTensor.cpp:280"
     ]
    }
   ],
   "source": [
    "u = c.view(1,-1,9)\n",
    "print(u.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.rand(1,3,8,5,5)\n",
    "h.unsqeuze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
