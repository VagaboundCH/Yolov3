{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = 26+10+4   #Grossbuchstaben, Zahlen, {.:/-}\n",
    "anchors = [10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326]\n",
    "leaky_relu_value = 0.1\n",
    "number_anchors = np.size(anchors)/6\n",
    "features = int(anchor_number*(4+1+number_classes))\n",
    "dimension = 3\n",
    "ignore_thres = 0.7\n",
    "\n",
    "\n",
    "class Yolo_v3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Yolo_v3, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(dimension,32,3,stride=1,padding=1)\n",
    "        self.batch_1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(32,64,3,stride=2,padding=1)\n",
    "        self.batch_2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(64,32,1,stride=1,padding=0)\n",
    "        self.batch_3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv_4 = nn.Conv2d(32,64,3,stride=1,padding=1)\n",
    "        self.batch_4 = nn.BatchNorm2d(64)\n",
    "\n",
    "\n",
    "        \n",
    "        self.conv_6 = nn.Conv2d(64,128,3,stride=2,padding=1)\n",
    "        self.batch_6 = nn.BatchNorm2d(128)\n",
    "            \n",
    "        self.conv_7 = nn.Conv2d(128,64,1,stride=1,padding=0)\n",
    "        self.batch_7 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_8 = nn.Conv2d(64,128,3,stride=1,padding=1)\n",
    "        self.batch_8 = nn.BatchNorm2d(128)\n",
    " \n",
    "\n",
    "          \n",
    "        self.conv_10 = nn.Conv2d(128,64,1,stride=1,padding=0)\n",
    "        self.batch_10 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_11 = nn.Conv2d(64,128,3,stride=1,padding=1)\n",
    "        self.batch_11 = nn.BatchNorm2d(128)\n",
    "          \n",
    "\n",
    "             \n",
    "        self.conv_13 = nn.Conv2d(128,256,3,stride=2,padding=1)\n",
    "        self.batch_13 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_14 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_14 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_15 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_15 = nn.BatchNorm2d(256)        \n",
    "        \n",
    "\n",
    "\n",
    "        self.conv_17 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_17 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_18 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_18 = nn.BatchNorm2d(256)\n",
    "        \n",
    "       \n",
    "    \n",
    "        \n",
    "        self.conv_38 = nn.Conv2d(256,512,3,stride=2,padding=1)\n",
    "        self.batch_38 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_39 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_39 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_40 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_40 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_42 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_42 = nn.BatchNorm2d(256)        \n",
    "        \n",
    "        self.conv_43 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_43 = nn.BatchNorm2d(512)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.conv_63 = nn.Conv2d(512,1024,3,stride=2,padding=1)\n",
    "        self.batch_63 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv_64 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_64 = nn.BatchNorm2d(512)        \n",
    "        \n",
    "        self.conv_65 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_65 = nn.BatchNorm2d(1024)  \n",
    "        \n",
    "\n",
    "        \n",
    "        self.conv_67 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_67 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_68 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_68 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_76 = nn.Conv2d(1024,512,1,stride=1,padding=0)\n",
    "        self.batch_76 = nn.BatchNorm2d(512)        \n",
    "        \n",
    "        self.conv_77 = nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
    "        self.batch_77 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv_82 = nn.Conv2d(1024,features,1,stride=1,padding=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_85 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_85 = nn.BatchNorm2d(256)       \n",
    "\n",
    "        self.convT_86 = nn.ConvTranspose2d(256,256,3,stride=2,padding=1,output_padding=1)\n",
    "        self.batch_86 = nn.BatchNorm2d(256) \n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv_88 = nn.Conv2d(512,256,1,stride=1,padding=0)\n",
    "        self.batch_88 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_89 = nn.Conv2d(256,512,3,stride=1,padding=1)\n",
    "        self.batch_89 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_94 = nn.Conv2d(512,features,1,stride=1,padding=0)\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        self.conv_97 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_97 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.convT_98 = nn.ConvTranspose2d(128,128,3,stride=2,padding=1,output_padding=1)\n",
    "        self.batch_98 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_100 = nn.Conv2d(256,128,1,stride=1,padding=0)\n",
    "        self.batch_100 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_101 = nn.Conv2d(128,256,3,stride=1,padding=1)\n",
    "        self.batch_101 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_106 = nn.Conv2d(256,features,1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        layer_1 = F.leaky_relu(self.batch_1(self.conv_1(inputs)),leaky_relu_value,True)\n",
    "        layer_2 = F.leaky_relu(self.batch_2(self.conv_2(layer_1)),leaky_relu_value,True)\n",
    "        layer_3 = F.leaky_relu(self.batch_3(self.conv_3(layer_2)),leaky_relu_value,True)\n",
    "        layer_4 = F.leaky_relu(self.batch_4(self.conv_4(layer_3)),leaky_relu_value,True)\n",
    "        layer_5 = layer_2 + layer_4\n",
    "        layer_6 = F.leaky_relu(self.batch_6(self.conv_6(layer_5)),leaky_relu_value,True)\n",
    "        layer_7 = F.leaky_relu(self.batch_7(self.conv_7(layer_6)),leaky_relu_value,True)\n",
    "        layer_8 = F.leaky_relu(self.batch_8(self.conv_8(layer_7)),leaky_relu_value,True)\n",
    "        layer_9 = layer_6 + layer_8\n",
    "        layer_10 = F.leaky_relu(self.batch_10(self.conv_10(layer_9)),leaky_relu_value,True)\n",
    "        layer_11 = F.leaky_relu(self.batch_11(self.conv_11(layer_10)),leaky_relu_value,True)\n",
    "        layer_12 = layer_9 + layer_11\n",
    "        layer_13 = F.leaky_relu(self.batch_13(self.conv_13(layer_12)),leaky_relu_value,True)\n",
    "        layer_14 = F.leaky_relu(self.batch_14(self.conv_14(layer_13)),leaky_relu_value,True)\n",
    "        layer_15 = F.leaky_relu(self.batch_15(self.conv_15(layer_14)),leaky_relu_value,True)\n",
    "        layer_16 = layer_13 + layer_15\n",
    "        layer_17 = F.leaky_relu(self.batch_17(self.conv_17(layer_16)),leaky_relu_value,True)\n",
    "        layer_18 = F.leaky_relu(self.batch_18(self.conv_18(layer_17)),leaky_relu_value,True)\n",
    "        layer_19 = layer_16 + layer_18      \n",
    "        layer_20 = F.leaky_relu(self.batch_17(self.conv_17(layer_19)),leaky_relu_value,True)\n",
    "        layer_21 = F.leaky_relu(self.batch_18(self.conv_18(layer_20)),leaky_relu_value,True)\n",
    "        layer_22 = layer_19 + layer_21\n",
    "        layer_23 = F.leaky_relu(self.batch_17(self.conv_17(layer_22)),leaky_relu_value,True)\n",
    "        layer_24 = F.leaky_relu(self.batch_18(self.conv_18(layer_23)),leaky_relu_value,True)\n",
    "        layer_25 = layer_22 + layer_24\n",
    "        layer_26 = F.leaky_relu(self.batch_17(self.conv_17(layer_25)),leaky_relu_value,True)\n",
    "        layer_27 = F.leaky_relu(self.batch_18(self.conv_18(layer_26)),leaky_relu_value,True)\n",
    "        layer_28 = layer_25 + layer_27\n",
    "        layer_29 = F.leaky_relu(self.batch_17(self.conv_17(layer_28)),leaky_relu_value,True)\n",
    "        layer_30 = F.leaky_relu(self.batch_18(self.conv_18(layer_29)),leaky_relu_value,True)\n",
    "        layer_31 = layer_28 + layer_30\n",
    "        layer_32 = F.leaky_relu(self.batch_17(self.conv_17(layer_31)),leaky_relu_value,True)\n",
    "        layer_33 = F.leaky_relu(self.batch_18(self.conv_18(layer_32)),leaky_relu_value,True)\n",
    "        layer_34 = layer_31 + layer_33\n",
    "        layer_35 = F.leaky_relu(self.batch_17(self.conv_17(layer_34)),leaky_relu_value,True)\n",
    "        layer_36 = F.leaky_relu(self.batch_18(self.conv_18(layer_35)),leaky_relu_value,True)\n",
    "        layer_37 = layer_34 + layer_36\n",
    "        layer_38 = F.leaky_relu(self.batch_38(self.conv_38(layer_37)),leaky_relu_value,True)\n",
    "        layer_39 = F.leaky_relu(self.batch_39(self.conv_39(layer_38)),leaky_relu_value,True)\n",
    "        layer_40 = F.leaky_relu(self.batch_40(self.conv_40(layer_39)),leaky_relu_value,True)\n",
    "        layer_41 = layer_38 + layer_40\n",
    "        layer_42 = F.leaky_relu(self.batch_42(self.conv_42(layer_41)),leaky_relu_value,True)\n",
    "        layer_43 = F.leaky_relu(self.batch_43(self.conv_43(layer_42)),leaky_relu_value,True)\n",
    "        layer_44 = layer_41 + layer_43\n",
    "        layer_45 = F.leaky_relu(self.batch_42(self.conv_42(layer_44)),leaky_relu_value,True)\n",
    "        layer_46 = F.leaky_relu(self.batch_43(self.conv_43(layer_45)),leaky_relu_value,True)\n",
    "        layer_47 = layer_44 + layer_46\n",
    "        layer_48 = F.leaky_relu(self.batch_42(self.conv_42(layer_47)),leaky_relu_value,True)\n",
    "        layer_49 = F.leaky_relu(self.batch_43(self.conv_43(layer_48)),leaky_relu_value,True)\n",
    "        layer_50 = layer_47 + layer_49\n",
    "        layer_51 = F.leaky_relu(self.batch_42(self.conv_42(layer_50)),leaky_relu_value,True)\n",
    "        layer_52 = F.leaky_relu(self.batch_43(self.conv_43(layer_51)),leaky_relu_value,True)\n",
    "        layer_53 = layer_50 + layer_52\n",
    "        layer_54 = F.leaky_relu(self.batch_42(self.conv_42(layer_53)),leaky_relu_value,True)\n",
    "        layer_55 = F.leaky_relu(self.batch_43(self.conv_43(layer_54)),leaky_relu_value,True)\n",
    "        layer_56 = layer_53 +layer_55\n",
    "        layer_57 = F.leaky_relu(self.batch_42(self.conv_42(layer_56)),leaky_relu_value,True)\n",
    "        layer_58 = F.leaky_relu(self.batch_43(self.conv_43(layer_57)),leaky_relu_value,True)\n",
    "        layer_59 = layer_56 + layer_58\n",
    "        layer_60 = F.leaky_relu(self.batch_42(self.conv_42(layer_59)),leaky_relu_value,True)\n",
    "        layer_61 = F.leaky_relu(self.batch_43(self.conv_43(layer_60)),leaky_relu_value,True)\n",
    "        layer_62 = layer_59 + layer_61\n",
    "        layer_63 = F.leaky_relu(self.batch_63(self.conv_63(layer_62)),leaky_relu_value,True)\n",
    "        layer_64 = F.leaky_relu(self.batch_64(self.conv_64(layer_63)),leaky_relu_value,True)\n",
    "        layer_65 = F.leaky_relu(self.batch_65(self.conv_65(layer_64)),leaky_relu_value,True)\n",
    "        layer_66 = layer_63 + layer_65\n",
    "        layer_67 = F.leaky_relu(self.batch_67(self.conv_67(layer_66)),leaky_relu_value,True)\n",
    "        layer_68 = F.leaky_relu(self.batch_68(self.conv_68(layer_67)),leaky_relu_value,True)\n",
    "        layer_69 = layer_66 + layer_68\n",
    "        layer_70 = F.leaky_relu(self.batch_67(self.conv_67(layer_69)),leaky_relu_value,True)\n",
    "        layer_71 = F.leaky_relu(self.batch_68(self.conv_68(layer_70)),leaky_relu_value,True)\n",
    "        layer_72 = layer_69 + layer_71\n",
    "        layer_73 = F.leaky_relu(self.batch_67(self.conv_67(layer_72)),leaky_relu_value,True)\n",
    "        layer_74 = F.leaky_relu(self.batch_68(self.conv_68(layer_73)),leaky_relu_value,True)\n",
    "        layer_75 = layer_72 + layer_74\n",
    "        layer_76 = F.leaky_relu(self.batch_76(self.conv_76(layer_75)),leaky_relu_value,True)\n",
    "        layer_77 = F.leaky_relu(self.batch_77(self.conv_77(layer_76)),leaky_relu_value,True)\n",
    "        layer_78 = F.leaky_relu(self.batch_76(self.conv_76(layer_77)),leaky_relu_value,True)\n",
    "        layer_79 = F.leaky_relu(self.batch_77(self.conv_77(layer_78)),leaky_relu_value,True)\n",
    "        layer_80 = F.leaky_relu(self.batch_76(self.conv_76(layer_79)),leaky_relu_value,True)\n",
    "        layer_81 = F.leaky_relu(self.batch_77(self.conv_77(layer_80)),leaky_relu_value,True)\n",
    "        layer_82 = self.conv_82(layer_81)\n",
    "        layer_83 = layer_82\n",
    "        layer_84 = layer_80   # 16x16\n",
    "        layer_85 = F.leaky_relu(self.batch_85(self.conv_85(layer_84)),leaky_relu_value,True)\n",
    "        layer_86 = F.leaky_relu(self.batch_86(self.convT_86(layer_85)),leaky_relu_value,True)\n",
    "        layer_87 = torch.cat((layer_60,layer_86),1)\n",
    "        layer_88 = F.leaky_relu(self.batch_88(self.conv_88(layer_87)),leaky_relu_value,True)\n",
    "        layer_89 = F.leaky_relu(self.batch_89(self.conv_89(layer_88)),leaky_relu_value,True)\n",
    "        layer_90 = F.leaky_relu(self.batch_88(self.conv_88(layer_89)),leaky_relu_value,True)\n",
    "        layer_91 = F.leaky_relu(self.batch_89(self.conv_89(layer_90)),leaky_relu_value,True)\n",
    "        layer_92 = F.leaky_relu(self.batch_88(self.conv_88(layer_91)),leaky_relu_value,True)\n",
    "        layer_93 = F.leaky_relu(self.batch_89(self.conv_89(layer_92)),leaky_relu_value,True)\n",
    "        layer_94 = self.conv_94(layer_93)\n",
    "        layer_95 = layer_94\n",
    "        layer_96 = layer_92   # 32x32\n",
    "        layer_97 = F.leaky_relu(self.batch_97(self.conv_97(layer_96)),leaky_relu_value,True)\n",
    "        layer_98 = F.leaky_relu(self.batch_98(self.convT_98(layer_97)),leaky_relu_value,True)\n",
    "        layer_99 = torch.cat((layer_35,layer_98),1)\n",
    "        layer_100 = F.leaky_relu(self.batch_100(self.conv_100(layer_99)),leaky_relu_value,True)\n",
    "        layer_101 = F.leaky_relu(self.batch_101(self.conv_101(layer_100)),leaky_relu_value,True)\n",
    "        layer_102 = F.leaky_relu(self.batch_100(self.conv_100(layer_101)),leaky_relu_value,True)\n",
    "        layer_103 = F.leaky_relu(self.batch_101(self.conv_101(layer_102)),leaky_relu_value,True)\n",
    "        layer_104 = F.leaky_relu(self.batch_100(self.conv_100(layer_103)),leaky_relu_value,True)\n",
    "        layer_105 = F.leaky_relu(self.batch_101(self.conv_101(layer_104)),leaky_relu_value,True)\n",
    "        layer_106 = self.conv_106(layer_105)\n",
    "        layer_107 = layer_106   # 64x64\n",
    "        return layer_83, layer_95, layer_106   # ...*3*(5+26+10+4) = 135\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yolo_v3(\n",
      "  (conv_1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_7): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_10): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_13): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_14): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_15): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_17): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_18): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_38): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_39): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_39): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_40): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_42): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_42): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_43): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_63): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch_63): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_64): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_64): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_65): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_65): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_67): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_67): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_68): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_68): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_76): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_76): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_77): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_77): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_82): Conv2d(1024, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_85): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_85): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (convT_86): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (batch_86): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_88): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_88): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_89): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_89): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_94): Conv2d(512, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_97): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_97): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (convT_98): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (batch_98): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_100): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (batch_100): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_101): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch_101): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_106): Conv2d(256, 135, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Yolo_v3()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 135, 16, 16]) torch.Size([1, 135, 32, 32]) torch.Size([1, 135, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 512, 512)\n",
    "output_layer_1, output_layer_2, output_layer_3 = net(x)\n",
    "print(output_layer_1.size(),output_layer_2.size(),output_layer_3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer_dim(output_layer):\n",
    "    batch_number, outputs, y, x = output_layer.shape\n",
    "    return output_layer_1.view(batch_number, anchor_number, 5, outputs/5/anchor_number, y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 9, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(output_layer_dim(output_layer_1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: yolo_filter_boxes\n",
    "\n",
    "def yolo_filter_boxes(output_layer, ignore_thresh  = 0.7):\n",
    "    \"\"\"Filters YOLO boxes by thresholding on object and class confidence.\n",
    "    \n",
    "    Arguments:\n",
    "    box_confidence -- tensor of shape (19, 19, 5, 1)   (1,anchor_number,1,y,x)\n",
    "    boxes -- tensor of shape (19, 19, 5, 4)   (1,anchor_number,4,y,x)\n",
    "    box_class_probs -- tensor of shape (19, 19, 5, 80)   (1,anchor_number,classes,y,x)\n",
    "    threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None,), containing the class probability score for selected boxes\n",
    "    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes\n",
    "    classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes\n",
    "    \n",
    "    Note: \"None\" is here because you don't know the exact number of selected boxes, as it depends on the threshold. \n",
    "    For example, the actual output size of scores would be (10,) if there are 10 boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    box_confidence = output_layer\n",
    "    box_confidence[:,:,0<ingore_tresh,:,:] = 0\n",
    "    \n",
    "    # Step 1: Compute box scores\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    box_scores = box_confidence[:,:,0,:,:,:] * box_class_probs[:,:,:,:,:,:] # 19x19x80   1,3,1,x,y * 1,3,\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 2: Find the box_classes thanks to the max box_scores, keep track of the corresponding score\n",
    "    ### START CODE HERE ### (≈ 2 lines)\n",
    "    box_classes = K.argmax(box_scores, axis = -1)  # 19x19x5x1  (1 class index)\n",
    "    box_class_scores = K.max(box_scores, axis = -1)  # 19x19x5x1 (1 class score)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 3: Create a filtering mask based on \"box_class_scores\" by using \"threshold\". The mask should have the\n",
    "    # same dimension as box_class_scores, and be True for the boxes you want to keep (with probability >= threshold)\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    filtering_mask = box_class_scores >= threshold\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 4: Apply the mask to scores, boxes and classes\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24])\n",
      "tensor([[-0.0648,  0.7843,  0.1301, -0.4658,  0.1693,  0.8792,  1.3256,\n",
      "         -0.2433, -0.1955, -1.3749,  1.2619,  0.1159,  0.9152, -1.4587,\n",
      "          0.2737, -0.5083,  1.0659, -1.1094,  0.9076,  1.1037, -0.3661,\n",
      "         -0.5086, -1.0312, -0.7361]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,24)\n",
    "print(a.size())\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 8])\n",
      "tensor([[[-0.0648,  0.7843,  0.1301, -0.4658,  0.1693,  0.8792,  1.3256,\n",
      "          -0.2433],\n",
      "         [-0.1955, -1.3749,  1.2619,  0.1159,  0.9152, -1.4587,  0.2737,\n",
      "          -0.5083],\n",
      "         [ 1.0659, -1.1094,  0.9076,  1.1037, -0.3661, -0.5086, -1.0312,\n",
      "          -0.7361]]])\n"
     ]
    }
   ],
   "source": [
    "b = a.view(1,3,8)\n",
    "print(b.size())\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([1, 1, 12, 12])\n",
      "b:  torch.Size([1, 1, 6, 6])\n",
      "c:  torch.Size([1, 1, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,1,12,12)\n",
    "conv = nn.Conv2d(1,1,3, stride=2,padding=1)\n",
    "convT = nn.ConvTranspose2d(1,1,3,stride=2,padding=0)\n",
    "\n",
    "b = conv(a)\n",
    "c = convT(b)\n",
    "\n",
    "print(\"a: \", a.size())\n",
    "print(\"b: \", b.size())\n",
    "print(\"c: \", c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d:  torch.Size([1, 1, 6, 6])\n",
      "ConvTranspose2d:  torch.Size([1, 1, 24, 24])\n",
      "Conv2d und ConvTranspose2d:  torch.Size([1, 1, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1, 1, 12, 12)   # Batch, Anzahl channels, X,Y \n",
    "downsample = nn.Conv2d(1, 1, 3, stride=2, padding=1)\n",
    "upsample = nn.ConvTranspose2d(1, 1, 3, stride=2, padding=1,output_padding=1)\n",
    "h = downsample(inputs)\n",
    "print('Conv2d: ', h.size())        # (1, 1, 6, 6)\n",
    "output = upsample(inputs)\n",
    "print('ConvTranspose2d: ', output.size())    # (1, 1, 12, 12)\n",
    "g = upsample(h)\n",
    "print('Conv2d und ConvTranspose2d: ', g.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 16, 16])\n",
      "torch.Size([1, 3, 40, 16, 16])\n",
      "torch.Size([1, 3, 40, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,45,16,16)\n",
    "b = torch.randn(1,3,45,16,16)\n",
    "a_1 = a[:,:,0:1,:,:]\n",
    "b_1 = b[:,:,5:45,:,:]\n",
    "print(a_1.size())\n",
    "print(b_1.size())\n",
    "c = a_1 * b_1\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-0.5632,  0.6375,  0.1176],\n",
      "           [ 0.5447, -1.1462,  0.1490],\n",
      "           [-0.1251, -0.1474, -1.1917]],\n",
      "\n",
      "          [[ 1.4222, -0.1715,  0.7544],\n",
      "           [-0.8280, -0.9577, -0.3616],\n",
      "           [-0.0319,  1.7941,  1.0353]],\n",
      "\n",
      "          [[ 0.6186,  2.3321,  1.5046],\n",
      "           [-1.1668,  0.9314, -1.3445],\n",
      "           [ 1.7020, -2.2355, -0.1922]],\n",
      "\n",
      "          [[ 1.1037, -1.1261,  1.2690],\n",
      "           [-0.1766, -0.5015, -1.4852],\n",
      "           [-0.7359,  0.4979, -1.5330]],\n",
      "\n",
      "          [[-1.2854, -0.4633,  0.6230],\n",
      "           [ 0.5019,  0.0472,  1.4350],\n",
      "           [-0.6152, -0.0931,  1.0234]],\n",
      "\n",
      "          [[-1.6129,  0.4488, -0.4820],\n",
      "           [-1.1157,  0.1372, -1.3236],\n",
      "           [-1.5912, -2.2227, -0.2241]],\n",
      "\n",
      "          [[ 0.5580, -1.1875,  0.6929],\n",
      "           [ 0.7481,  0.0935, -1.2490],\n",
      "           [-0.3822, -2.0549, -0.5237]],\n",
      "\n",
      "          [[-0.3973,  0.3810,  0.8703],\n",
      "           [-1.0691, -1.7368, -1.3901],\n",
      "           [ 0.7283,  0.8566,  0.8124]]],\n",
      "\n",
      "\n",
      "         [[[-0.0612,  0.9618, -0.3454],\n",
      "           [-0.6440, -0.5219,  1.6592],\n",
      "           [ 0.2547, -0.0360,  0.8362]],\n",
      "\n",
      "          [[ 1.1599, -1.0799, -0.0946],\n",
      "           [-0.5724, -0.8783,  1.4978],\n",
      "           [ 1.9730, -0.6517,  0.3818]],\n",
      "\n",
      "          [[-0.8657,  1.6474, -0.0236],\n",
      "           [ 0.4914, -0.8845, -0.4954],\n",
      "           [ 0.3094,  1.4308,  0.6290]],\n",
      "\n",
      "          [[ 0.5496, -0.3941, -1.0050],\n",
      "           [-1.2025, -0.9625,  3.5999],\n",
      "           [-0.8817, -1.0656,  1.2344]],\n",
      "\n",
      "          [[ 0.8667,  1.0035,  0.2771],\n",
      "           [-0.7853, -0.2350,  0.6939],\n",
      "           [-0.7028,  0.1995,  2.1824]],\n",
      "\n",
      "          [[-0.2028,  0.1187, -0.8554],\n",
      "           [ 1.1300,  0.3336,  0.6333],\n",
      "           [ 0.7094, -1.9753, -0.3694]],\n",
      "\n",
      "          [[-2.6496,  0.6344, -1.2281],\n",
      "           [-0.2903, -1.3730,  0.8903],\n",
      "           [ 0.0646, -0.1108, -0.6684]],\n",
      "\n",
      "          [[ 1.5021,  1.4429, -0.3047],\n",
      "           [-0.2504, -0.7102,  0.8417],\n",
      "           [ 2.7909,  0.2577, -0.6023]]],\n",
      "\n",
      "\n",
      "         [[[ 0.4032,  0.5624, -1.3425],\n",
      "           [ 1.1347, -1.3322,  0.0520],\n",
      "           [-0.5015,  0.6539, -0.4596]],\n",
      "\n",
      "          [[-0.6097, -1.3807, -1.4273],\n",
      "           [ 0.7307, -0.4447,  0.4197],\n",
      "           [ 0.3383, -1.2180,  1.4079]],\n",
      "\n",
      "          [[-1.0507, -0.8582, -1.5619],\n",
      "           [-1.3115, -0.5419,  1.1295],\n",
      "           [ 0.6709,  1.0720,  0.3408]],\n",
      "\n",
      "          [[-0.2866,  0.3248,  1.1518],\n",
      "           [-0.0245, -1.0488,  1.2050],\n",
      "           [ 0.9960, -1.5708, -0.0846]],\n",
      "\n",
      "          [[ 0.8928,  1.2801, -0.7385],\n",
      "           [-0.2973,  1.4566, -0.7409],\n",
      "           [ 0.2575,  0.6774,  1.2078]],\n",
      "\n",
      "          [[-0.0457,  0.2903,  2.3342],\n",
      "           [-0.0829, -1.5931,  1.2346],\n",
      "           [-0.7915,  1.8921, -0.0874]],\n",
      "\n",
      "          [[ 0.0110, -0.3751,  1.7428],\n",
      "           [-0.2006, -0.6385, -0.0361],\n",
      "           [ 1.7169,  0.5081,  0.9622]],\n",
      "\n",
      "          [[-0.2139, -0.2730,  0.2823],\n",
      "           [ 0.4141, -0.3532, -0.0470],\n",
      "           [-1.2433,  0.3206,  0.0021]]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,8,3,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.5632,  0.6375,  0.1176],\n",
      "          [ 0.5447, -1.1462,  0.1490],\n",
      "          [-0.1251, -0.1474, -1.1917]],\n",
      "\n",
      "         [[-0.0612,  0.9618, -0.3454],\n",
      "          [-0.6440, -0.5219,  1.6592],\n",
      "          [ 0.2547, -0.0360,  0.8362]],\n",
      "\n",
      "         [[ 0.4032,  0.5624, -1.3425],\n",
      "          [ 1.1347, -1.3322,  0.0520],\n",
      "          [-0.5015,  0.6539, -0.4596]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a[:,:,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_output[:,:,0,:,:] => pc\n",
    "# layer_output[:,:,1,:,:] => bx\n",
    "# layer_output[:,:,2,:,:] => by\n",
    "# layer_output[:,:,3,:,:] => tx\n",
    "# layer_output[:,:,4,:,:] => ty\n",
    "# layer_output[:,:,5,:,:] => c1\n",
    "# layer_output[:,:,n,:,:] => cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-1.6129,  0.4488, -0.4820],\n",
      "           [-1.1157,  0.1372, -1.3236],\n",
      "           [-1.5912, -2.2227, -0.2241]],\n",
      "\n",
      "          [[ 0.5580, -1.1875,  0.6929],\n",
      "           [ 0.7481,  0.0935, -1.2490],\n",
      "           [-0.3822, -2.0549, -0.5237]],\n",
      "\n",
      "          [[-0.3973,  0.3810,  0.8703],\n",
      "           [-1.0691, -1.7368, -1.3901],\n",
      "           [ 0.7283,  0.8566,  0.8124]]],\n",
      "\n",
      "\n",
      "         [[[-0.2028,  0.1187, -0.8554],\n",
      "           [ 1.1300,  0.3336,  0.6333],\n",
      "           [ 0.7094, -1.9753, -0.3694]],\n",
      "\n",
      "          [[-2.6496,  0.6344, -1.2281],\n",
      "           [-0.2903, -1.3730,  0.8903],\n",
      "           [ 0.0646, -0.1108, -0.6684]],\n",
      "\n",
      "          [[ 1.5021,  1.4429, -0.3047],\n",
      "           [-0.2504, -0.7102,  0.8417],\n",
      "           [ 2.7909,  0.2577, -0.6023]]],\n",
      "\n",
      "\n",
      "         [[[-0.0457,  0.2903,  2.3342],\n",
      "           [-0.0829, -1.5931,  1.2346],\n",
      "           [-0.7915,  1.8921, -0.0874]],\n",
      "\n",
      "          [[ 0.0110, -0.3751,  1.7428],\n",
      "           [-0.2006, -0.6385, -0.0361],\n",
      "           [ 1.7169,  0.5081,  0.9622]],\n",
      "\n",
      "          [[-0.2139, -0.2730,  0.2823],\n",
      "           [ 0.4141, -0.3532, -0.0470],\n",
      "           [-1.2433,  0.3206,  0.0021]]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a[:,:,5:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_surpression(layer_output, ignore_threshold = 0.7):\n",
    "    box_scores = torch.mul(layer_output[:,:,5:,:,:], layer_output[:,:,0,:,:]) # confidence * class score\n",
    "    torch.cat((c[:,0,:,:,:], c[:,1,:,:,:], c[:,2,:,:,:]),1)\n",
    "    return box_scores\n",
    "\n",
    "    # class_scores = torch.mul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,8,3,3)\n",
    "b = non_max_surpression(a,0.7)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n",
      "tensor([[[[[-1.1322,  0.0582, -0.0783],\n",
      "           [ 0.1537, -0.2537,  0.0696],\n",
      "           [-1.8338,  0.8620, -1.2413]],\n",
      "\n",
      "          [[-0.7102, -0.4030, -0.1584],\n",
      "           [ 0.5782, -0.1731,  0.6507],\n",
      "           [ 0.0943, -0.6497,  0.1862]],\n",
      "\n",
      "          [[ 0.4290,  1.6862,  0.0593],\n",
      "           [ 0.1548,  0.3242, -0.0112],\n",
      "           [ 1.2507,  1.4523, -0.1174]]],\n",
      "\n",
      "\n",
      "         [[[ 0.8571, -0.2422, -0.7888],\n",
      "           [ 0.1674,  0.1334,  4.1811],\n",
      "           [ 5.1975,  1.1366, -0.7760]],\n",
      "\n",
      "          [[-0.0089,  0.5696, -0.0306],\n",
      "           [-1.3017, -0.3081,  0.8529],\n",
      "           [ 0.1151, -3.7696,  0.5952]],\n",
      "\n",
      "          [[-0.2694, -0.1435, -0.3717],\n",
      "           [-0.4499,  0.6509,  0.0265],\n",
      "           [-1.2660, -1.4730, -0.6306]]],\n",
      "\n",
      "\n",
      "         [[[ 0.5426,  0.0043,  1.8324],\n",
      "           [-1.3500,  0.2663,  0.3317],\n",
      "           [ 0.3866,  0.1965,  0.4595]],\n",
      "\n",
      "          [[-2.7343, -0.4323, -1.5813],\n",
      "           [ 0.0145,  0.9664,  0.8758],\n",
      "           [-0.1254,  1.7350, -0.2531]],\n",
      "\n",
      "          [[-0.0274, -0.0950,  1.4049],\n",
      "           [-0.1042,  0.3156,  0.0785],\n",
      "           [ 0.7220,  1.0007, -0.3720]]]]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.mul(a[:,:,5:,:,:], a[:,:,0,:,:])\n",
    "print(b.size())\n",
    "# b[b<0.1] = 0\n",
    "# b[b>=0.1] = 1\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   box_classes = K.argmax(box_scores, axis = -1)  # 19x19x5x1  (1 class index)\n",
    "#  box_class_scores = K.max(box_scores, axis = -1)  # 19x19x5x1 (1 class score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0.1453,  0.3222, -0.8677],\n",
      "           [ 0.3942, -0.8767,  0.0186],\n",
      "           [-0.0429, -0.5691, -0.1548]],\n",
      "\n",
      "          [[ 1.4984, -0.6764, -0.3858],\n",
      "           [-0.1393, -0.5445, -0.3784],\n",
      "           [-0.0058,  0.9321,  1.5658]],\n",
      "\n",
      "          [[-0.0042, -0.9975,  0.1681],\n",
      "           [-0.7926,  1.1236,  0.0412],\n",
      "           [ 0.2972, -0.1403, -0.3645]],\n",
      "\n",
      "          [[-0.3765, -0.8055, -0.6821],\n",
      "           [-0.3558,  2.1598,  2.1103],\n",
      "           [ 0.1300, -0.3741,  0.0757]],\n",
      "\n",
      "          [[-2.5740, -0.5574, -0.7684],\n",
      "           [ 1.2945, -0.0641, -0.8182],\n",
      "           [-2.1312, -0.6864, -0.2527]],\n",
      "\n",
      "          [[-0.8003,  0.7683, -1.0649],\n",
      "           [ 1.8570, -0.8143, -0.5750],\n",
      "           [-1.3593, -0.9354, -0.1103]],\n",
      "\n",
      "          [[ 0.0672,  0.3824,  0.7212],\n",
      "           [ 2.9575, -1.2002, -1.2147],\n",
      "           [ 1.3152, -0.3910, -1.7388]],\n",
      "\n",
      "          [[-1.1646,  0.1989,  0.9756],\n",
      "           [-1.2275, -0.3666, -0.0395],\n",
      "           [ 0.1581, -1.8811, -0.5720]]],\n",
      "\n",
      "\n",
      "         [[[-0.6556,  0.6233,  1.3132],\n",
      "           [ 0.8257, -1.1156,  0.1855],\n",
      "           [-0.2171,  1.7124, -1.4058]],\n",
      "\n",
      "          [[-1.0323, -1.0515,  0.7021],\n",
      "           [-1.4100, -0.3313,  1.3009],\n",
      "           [ 1.1451, -0.8084, -0.0901]],\n",
      "\n",
      "          [[-0.4183, -1.9805,  1.1174],\n",
      "           [ 1.3895, -0.2220,  0.0268],\n",
      "           [ 0.8606, -0.3749,  1.3940]],\n",
      "\n",
      "          [[-0.3879, -0.9756,  0.1065],\n",
      "           [ 0.8104,  1.0158,  0.8491],\n",
      "           [-2.4179,  1.1393,  0.2565]],\n",
      "\n",
      "          [[ 0.0105, -1.9618, -0.4124],\n",
      "           [ 2.3191,  0.2469, -1.8353],\n",
      "           [-0.4983, -0.7022, -0.1076]],\n",
      "\n",
      "          [[-1.8747, -1.6715, -1.3859],\n",
      "           [-0.5295, -0.5642, -0.6924],\n",
      "           [-0.5394,  0.5514,  1.5575]],\n",
      "\n",
      "          [[ 2.5219,  0.6018,  0.9833],\n",
      "           [ 0.0880,  0.2821,  0.7378],\n",
      "           [-0.7471, -1.3530, -1.9507]],\n",
      "\n",
      "          [[ 0.7796, -0.1643, -0.4532],\n",
      "           [-1.5558, -0.2120,  0.2170],\n",
      "           [-1.5331, -0.8501,  1.0216]]],\n",
      "\n",
      "\n",
      "         [[[ 0.6638, -0.6788,  0.4855],\n",
      "           [ 0.7685,  2.4586,  0.8653],\n",
      "           [ 1.3930, -0.8926,  0.7569]],\n",
      "\n",
      "          [[ 0.0404,  0.6929, -0.9280],\n",
      "           [ 1.5205,  1.0830,  0.1294],\n",
      "           [-0.6133,  0.8962,  0.8376]],\n",
      "\n",
      "          [[ 0.4329,  0.9391, -0.1937],\n",
      "           [-0.2987,  0.1866,  0.7659],\n",
      "           [ 0.0021,  0.9695,  0.3558]],\n",
      "\n",
      "          [[-0.4868,  0.3647, -0.0406],\n",
      "           [-1.7198, -3.5157,  1.2544],\n",
      "           [ 1.7959,  0.4936, -0.0069]],\n",
      "\n",
      "          [[ 0.2877,  1.0932,  1.6533],\n",
      "           [-0.4925, -1.0968,  0.2994],\n",
      "           [ 2.5744,  0.3388, -1.0890]],\n",
      "\n",
      "          [[-0.1025,  0.3199,  0.5447],\n",
      "           [-0.9048,  0.0820,  0.1154],\n",
      "           [-0.2631,  0.2083, -2.6952]],\n",
      "\n",
      "          [[-0.3947, -1.2871,  1.6479],\n",
      "           [-0.1356, -1.6607,  1.6340],\n",
      "           [ 1.0280,  1.4279, -0.7323]],\n",
      "\n",
      "          [[-1.3484,  1.7652, -0.8194],\n",
      "           [-0.1863, -0.3945,  0.2421],\n",
      "           [-0.3758, -0.3954,  0.3801]]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,8,3,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-0.8003,  0.7683, -1.0649],\n",
      "           [ 1.8570, -0.8143, -0.5750],\n",
      "           [-1.3593, -0.9354, -0.1103]],\n",
      "\n",
      "          [[ 0.0672,  0.3824,  0.7212],\n",
      "           [ 2.9575, -1.2002, -1.2147],\n",
      "           [ 1.3152, -0.3910, -1.7388]],\n",
      "\n",
      "          [[-1.1646,  0.1989,  0.9756],\n",
      "           [-1.2275, -0.3666, -0.0395],\n",
      "           [ 0.1581, -1.8811, -0.5720]]],\n",
      "\n",
      "\n",
      "         [[[-1.8747, -1.6715, -1.3859],\n",
      "           [-0.5295, -0.5642, -0.6924],\n",
      "           [-0.5394,  0.5514,  1.5575]],\n",
      "\n",
      "          [[ 2.5219,  0.6018,  0.9833],\n",
      "           [ 0.0880,  0.2821,  0.7378],\n",
      "           [-0.7471, -1.3530, -1.9507]],\n",
      "\n",
      "          [[ 0.7796, -0.1643, -0.4532],\n",
      "           [-1.5558, -0.2120,  0.2170],\n",
      "           [-1.5331, -0.8501,  1.0216]]],\n",
      "\n",
      "\n",
      "         [[[-0.1025,  0.3199,  0.5447],\n",
      "           [-0.9048,  0.0820,  0.1154],\n",
      "           [-0.2631,  0.2083, -2.6952]],\n",
      "\n",
      "          [[-0.3947, -1.2871,  1.6479],\n",
      "           [-0.1356, -1.6607,  1.6340],\n",
      "           [ 1.0280,  1.4279, -0.7323]],\n",
      "\n",
      "          [[-1.3484,  1.7652, -0.8194],\n",
      "           [-0.1863, -0.3945,  0.2421],\n",
      "           [-0.3758, -0.3954,  0.3801]]]]])\n"
     ]
    }
   ],
   "source": [
    "c = a[:,:,5:,:,:]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n",
      "torch.Size([1, 9, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "c1 = torch.cat((c[:,0,:,:,:], c[:,1,:,:,:], c[:,2,:,:,:]),1)\n",
    "print(c.size())\n",
    "print(c1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.8003,  0.7683, -1.0649],\n",
      "          [ 1.8570, -0.8143, -0.5750],\n",
      "          [-1.3593, -0.9354, -0.1103]],\n",
      "\n",
      "         [[ 0.0672,  0.3824,  0.7212],\n",
      "          [ 2.9575, -1.2002, -1.2147],\n",
      "          [ 1.3152, -0.3910, -1.7388]],\n",
      "\n",
      "         [[-1.1646,  0.1989,  0.9756],\n",
      "          [-1.2275, -0.3666, -0.0395],\n",
      "          [ 0.1581, -1.8811, -0.5720]],\n",
      "\n",
      "         [[-1.8747, -1.6715, -1.3859],\n",
      "          [-0.5295, -0.5642, -0.6924],\n",
      "          [-0.5394,  0.5514,  1.5575]],\n",
      "\n",
      "         [[ 2.5219,  0.6018,  0.9833],\n",
      "          [ 0.0880,  0.2821,  0.7378],\n",
      "          [-0.7471, -1.3530, -1.9507]],\n",
      "\n",
      "         [[ 0.7796, -0.1643, -0.4532],\n",
      "          [-1.5558, -0.2120,  0.2170],\n",
      "          [-1.5331, -0.8501,  1.0216]],\n",
      "\n",
      "         [[-0.1025,  0.3199,  0.5447],\n",
      "          [-0.9048,  0.0820,  0.1154],\n",
      "          [-0.2631,  0.2083, -2.6952]],\n",
      "\n",
      "         [[-0.3947, -1.2871,  1.6479],\n",
      "          [-0.1356, -1.6607,  1.6340],\n",
      "          [ 1.0280,  1.4279, -0.7323]],\n",
      "\n",
      "         [[-1.3484,  1.7652, -0.8194],\n",
      "          [-0.1863, -0.3945,  0.2421],\n",
      "          [-0.3758, -0.3954,  0.3801]]]])\n"
     ]
    }
   ],
   "source": [
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9833)\n",
      "tensor([[[ 2.5219,  1.7652,  1.6479],\n",
      "         [ 2.9575,  0.2821,  1.6340],\n",
      "         [ 1.3152,  1.4279,  1.5575]]])\n",
      "torch.Size([1, 3, 3])\n",
      "tensor([[[ 4,  8,  7],\n",
      "         [ 1,  4,  7],\n",
      "         [ 1,  7,  3]]])\n",
      "1 3 3\n"
     ]
    }
   ],
   "source": [
    "d_max, d_max_index = torch.max(c1,1)\n",
    "print(c1[0,4,0,2])\n",
    "print(d_max)\n",
    "print(d_max_index.size())\n",
    "print(d_max_index)\n",
    "x,y,z = d_max.shape\n",
    "print(x,y,z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(tmp):\n",
    "    tmp1 = torch.cat((tmp[:,0,:,:,:], c[:,1,:,:,:], c[:,2,:,:,:]),1)\n",
    "    d_max, d_max_index = torch.max(tmp1,1)\n",
    "    batch_size, tmp_number_classes, y, x = tmp1.shape\n",
    "    tmp_tensor = torch.zeros(batch_size, tmp_number_classes, y, x)\n",
    "    \n",
    "    for i in range(y):\n",
    "        for j in range(x):\n",
    "            position = d_max_index[0,i,j]\n",
    "            tmp_tensor[0,position,i,j] = 1 \n",
    "    return tmp_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u = helper(c)\n",
    "#print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 3, 3])\n",
      "torch.Size([1, 9, 3, 3])\n",
      "tensor([[[[-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 2.9575, -0.0000, -0.0000],\n",
      "          [ 1.3152, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  1.5575]],\n",
      "\n",
      "         [[ 2.5219,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.2821,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000,  1.6479],\n",
      "          [-0.0000, -0.0000,  1.6340],\n",
      "          [ 0.0000,  1.4279, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  1.7652, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "print(c1.size())\n",
    "print(u.size())\n",
    "print(torch.mul(c1,u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 3, 3])\n",
      "tensor([[[[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]]]])\n"
     ]
    }
   ],
   "source": [
    "t_zero = torch.zeros(1,9,3,3)\n",
    "print(t_zero.size())\n",
    "print(t_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.1290,  0.4124, -1.7386],\n",
      "          [-0.7921, -0.4450, -0.8708],\n",
      "          [ 0.4727, -0.4014,  1.2026]],\n",
      "\n",
      "         [[ 0.4062,  1.9689,  0.7067],\n",
      "          [-0.8952, -0.7421,  0.3678],\n",
      "          [-0.2262,  1.4510, -0.2578]],\n",
      "\n",
      "         [[ 1.0477, -1.0093, -0.5598],\n",
      "          [ 1.2956, -0.5233, -0.8708],\n",
      "          [ 0.1761, -0.9165, -0.1610]]]])\n"
     ]
    }
   ],
   "source": [
    "n = a[:,:,4,:,:]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524543037166\\work\\aten\\src\\th\\generic/THTensor.cpp:280",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-284-4e7892ca61c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524543037166\\work\\aten\\src\\th\\generic/THTensor.cpp:280"
     ]
    }
   ],
   "source": [
    "u = c.view(1,-1,9)\n",
    "print(u.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.rand(1,3,8,5,5)\n",
    "h.unsqeuze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
